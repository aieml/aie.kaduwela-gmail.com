{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 01 Diabetic Related Complications and Risk Level\n",
    "\n",
    "## 1.1 Diabetic Related Complications\n",
    "\n",
    "### inputs\n",
    "\n",
    "patient_code\tfemale_gender\tage_years\teducation_level\teducation_standard\teducation_advanced\tbmi_kgm2\tdiabetes_type\tdmt1\tdiabetes_duration\tinsulin_treatment\tonly_med_treatment\thba1c_percent\thba1c_mmol\n",
    "\n",
    "### Outputs\n",
    "\n",
    "Probabilities (Out of 100%)\n",
    "\n",
    "nephropathy\tretinopathy\tneuropathy\tfoot_ulcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset=pd.read_csv('diabetic.csv').values\n",
    "data=dataset[:,1:14]\n",
    "target_1=dataset[:,14]\n",
    "target_2=dataset[:,15]\n",
    "target_3=dataset[:,16]\n",
    "target_4=dataset[:,17]\n",
    "\n",
    "np.save('data_diabetic_complications',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(data)\n",
    "xscale=scaler_x.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    import keras.models as models\n",
    "    import keras.layers as layers\n",
    "    import keras.optimizers as optimizers\n",
    "    from keras.layers import Dropout\n",
    "    import numpy as np\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot(name):\n",
    "    \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('data/graphs/'+name+'_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model acc')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.savefig('data/graphs/'+name+'_acc.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nephropathy retinopathy neuropathy foot_ulcer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 1s 2ms/step - loss: 0.6994 - accuracy: 0.4799 - val_loss: 0.6496 - val_accuracy: 0.9487\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.6327 - accuracy: 0.8736 - val_loss: 0.5785 - val_accuracy: 0.9487\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.5532 - accuracy: 0.8908 - val_loss: 0.4552 - val_accuracy: 0.9487\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4451 - accuracy: 0.8908 - val_loss: 0.3034 - val_accuracy: 0.9487\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3868 - accuracy: 0.8908 - val_loss: 0.2325 - val_accuracy: 0.9487\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.3580 - accuracy: 0.8908 - val_loss: 0.2218 - val_accuracy: 0.9487\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3652 - accuracy: 0.8908 - val_loss: 0.2290 - val_accuracy: 0.9487\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.3407 - accuracy: 0.8908 - val_loss: 0.2393 - val_accuracy: 0.9487\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 129us/step - loss: 0.3362 - accuracy: 0.8908 - val_loss: 0.2335 - val_accuracy: 0.9487\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3438 - accuracy: 0.8908 - val_loss: 0.2309 - val_accuracy: 0.9487\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.3373 - accuracy: 0.8908 - val_loss: 0.2289 - val_accuracy: 0.9487\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 135us/step - loss: 0.3330 - accuracy: 0.8908 - val_loss: 0.2295 - val_accuracy: 0.9487\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3254 - accuracy: 0.8908 - val_loss: 0.2350 - val_accuracy: 0.9487\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 135us/step - loss: 0.3340 - accuracy: 0.8908 - val_loss: 0.2327 - val_accuracy: 0.9487\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.3344 - accuracy: 0.8908 - val_loss: 0.2336 - val_accuracy: 0.9487\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.3191 - accuracy: 0.8908 - val_loss: 0.2327 - val_accuracy: 0.9487\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.3231 - accuracy: 0.8908 - val_loss: 0.2259 - val_accuracy: 0.9487\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3193 - accuracy: 0.8908 - val_loss: 0.2263 - val_accuracy: 0.9487\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.3259 - accuracy: 0.8908 - val_loss: 0.2340 - val_accuracy: 0.9487\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.3182 - accuracy: 0.8908 - val_loss: 0.2305 - val_accuracy: 0.9487\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.3206 - accuracy: 0.8908 - val_loss: 0.2300 - val_accuracy: 0.9487\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.3169 - accuracy: 0.8908 - val_loss: 0.2300 - val_accuracy: 0.9487\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3161 - accuracy: 0.8908 - val_loss: 0.2251 - val_accuracy: 0.9487\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3038 - accuracy: 0.8908 - val_loss: 0.2262 - val_accuracy: 0.9487\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3180 - accuracy: 0.8908 - val_loss: 0.2237 - val_accuracy: 0.9487\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.3091 - accuracy: 0.8908 - val_loss: 0.2267 - val_accuracy: 0.9487\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3077 - accuracy: 0.8908 - val_loss: 0.2277 - val_accuracy: 0.9487\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.3025 - accuracy: 0.8908 - val_loss: 0.2207 - val_accuracy: 0.9487\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.3011 - accuracy: 0.8908 - val_loss: 0.2217 - val_accuracy: 0.9487\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3021 - accuracy: 0.8908 - val_loss: 0.2215 - val_accuracy: 0.9487\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.3064 - accuracy: 0.8908 - val_loss: 0.2250 - val_accuracy: 0.9487\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3127 - accuracy: 0.8908 - val_loss: 0.2231 - val_accuracy: 0.9487\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3045 - accuracy: 0.8908 - val_loss: 0.2233 - val_accuracy: 0.9487\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.2009 - accuracy: 0.93 - 0s 121us/step - loss: 0.2913 - accuracy: 0.8908 - val_loss: 0.2189 - val_accuracy: 0.9487\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.2964 - accuracy: 0.8908 - val_loss: 0.2185 - val_accuracy: 0.9487\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3108 - accuracy: 0.8908 - val_loss: 0.2208 - val_accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3016 - accuracy: 0.8908 - val_loss: 0.2209 - val_accuracy: 0.9487\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3060 - accuracy: 0.8908 - val_loss: 0.2195 - val_accuracy: 0.9487\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2892 - accuracy: 0.8908 - val_loss: 0.2205 - val_accuracy: 0.9487\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.87 - 0s 95us/step - loss: 0.2965 - accuracy: 0.8908 - val_loss: 0.2180 - val_accuracy: 0.9487\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2986 - accuracy: 0.8908 - val_loss: 0.2180 - val_accuracy: 0.9487\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2831 - accuracy: 0.8908 - val_loss: 0.2200 - val_accuracy: 0.9487\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2941 - accuracy: 0.8908 - val_loss: 0.2191 - val_accuracy: 0.9487\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2938 - accuracy: 0.8908 - val_loss: 0.2152 - val_accuracy: 0.9487\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2900 - accuracy: 0.8908 - val_loss: 0.2182 - val_accuracy: 0.9487\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2893 - accuracy: 0.8908 - val_loss: 0.2146 - val_accuracy: 0.9487\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2974 - accuracy: 0.8908 - val_loss: 0.2183 - val_accuracy: 0.9487\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2924 - accuracy: 0.8908 - val_loss: 0.2176 - val_accuracy: 0.9487\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2956 - accuracy: 0.8908 - val_loss: 0.2134 - val_accuracy: 0.9487\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2873 - accuracy: 0.8908 - val_loss: 0.2142 - val_accuracy: 0.9487\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2892 - accuracy: 0.8908 - val_loss: 0.2161 - val_accuracy: 0.9487\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2850 - accuracy: 0.8908 - val_loss: 0.2148 - val_accuracy: 0.9487\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2876 - accuracy: 0.8908 - val_loss: 0.2181 - val_accuracy: 0.9487\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.2862 - accuracy: 0.8908 - val_loss: 0.2173 - val_accuracy: 0.9487\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2943 - accuracy: 0.8908 - val_loss: 0.2159 - val_accuracy: 0.9487\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 104us/step - loss: 0.2969 - accuracy: 0.8908 - val_loss: 0.2155 - val_accuracy: 0.9487\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2861 - accuracy: 0.8908 - val_loss: 0.2163 - val_accuracy: 0.9487\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2873 - accuracy: 0.8908 - val_loss: 0.2167 - val_accuracy: 0.9487\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2855 - accuracy: 0.8908 - val_loss: 0.2149 - val_accuracy: 0.9487\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2798 - accuracy: 0.8908 - val_loss: 0.2150 - val_accuracy: 0.9487\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2868 - accuracy: 0.8908 - val_loss: 0.2123 - val_accuracy: 0.9487\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2755 - accuracy: 0.8908 - val_loss: 0.2139 - val_accuracy: 0.9487\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2747 - accuracy: 0.8908 - val_loss: 0.2120 - val_accuracy: 0.9487\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2735 - accuracy: 0.8908 - val_loss: 0.2111 - val_accuracy: 0.9487\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 111us/step - loss: 0.2914 - accuracy: 0.8908 - val_loss: 0.2148 - val_accuracy: 0.9487\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2782 - accuracy: 0.8908 - val_loss: 0.2199 - val_accuracy: 0.9487\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2771 - accuracy: 0.8908 - val_loss: 0.2149 - val_accuracy: 0.9487\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2775 - accuracy: 0.8908 - val_loss: 0.2132 - val_accuracy: 0.9487\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2737 - accuracy: 0.8908 - val_loss: 0.2154 - val_accuracy: 0.9487\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2824 - accuracy: 0.8908 - val_loss: 0.2151 - val_accuracy: 0.9487\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2760 - accuracy: 0.8908 - val_loss: 0.2125 - val_accuracy: 0.9487\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2756 - accuracy: 0.8908 - val_loss: 0.2171 - val_accuracy: 0.9487\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2686 - accuracy: 0.8908 - val_loss: 0.2143 - val_accuracy: 0.9487\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2746 - accuracy: 0.8908 - val_loss: 0.2136 - val_accuracy: 0.9487\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2729 - accuracy: 0.8908 - val_loss: 0.2133 - val_accuracy: 0.9487\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2703 - accuracy: 0.8908 - val_loss: 0.2155 - val_accuracy: 0.9487\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.2081 - accuracy: 0.90 - 0s 92us/step - loss: 0.2830 - accuracy: 0.8908 - val_loss: 0.2125 - val_accuracy: 0.9487\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2641 - accuracy: 0.8908 - val_loss: 0.2106 - val_accuracy: 0.9487\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2772 - accuracy: 0.8908 - val_loss: 0.2102 - val_accuracy: 0.9487\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2822 - accuracy: 0.8908 - val_loss: 0.2124 - val_accuracy: 0.9487\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2799 - accuracy: 0.8908 - val_loss: 0.2132 - val_accuracy: 0.9487\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2645 - accuracy: 0.8908 - val_loss: 0.2114 - val_accuracy: 0.9487\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.2651 - accuracy: 0.8908 - val_loss: 0.2094 - val_accuracy: 0.9487\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2728 - accuracy: 0.8908 - val_loss: 0.2086 - val_accuracy: 0.9487\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2707 - accuracy: 0.8908 - val_loss: 0.2090 - val_accuracy: 0.9487\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2723 - accuracy: 0.8937 - val_loss: 0.2121 - val_accuracy: 0.9487\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.87 - 0s 101us/step - loss: 0.2789 - accuracy: 0.8908 - val_loss: 0.2111 - val_accuracy: 0.9487\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2726 - accuracy: 0.8937 - val_loss: 0.2108 - val_accuracy: 0.9487\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2761 - accuracy: 0.8908 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2581 - accuracy: 0.8937 - val_loss: 0.2072 - val_accuracy: 0.9487\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2769 - accuracy: 0.8937 - val_loss: 0.2079 - val_accuracy: 0.9487\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2638 - accuracy: 0.8908 - val_loss: 0.2110 - val_accuracy: 0.9487\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2768 - accuracy: 0.8908 - val_loss: 0.2103 - val_accuracy: 0.9487\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2651 - accuracy: 0.8908 - val_loss: 0.2072 - val_accuracy: 0.9487\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2678 - accuracy: 0.8937 - val_loss: 0.2058 - val_accuracy: 0.9487\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2636 - accuracy: 0.8937 - val_loss: 0.2076 - val_accuracy: 0.9487\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2761 - accuracy: 0.8908 - val_loss: 0.2094 - val_accuracy: 0.9487\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2726 - accuracy: 0.8937 - val_loss: 0.2089 - val_accuracy: 0.9487\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2688 - accuracy: 0.8908 - val_loss: 0.2071 - val_accuracy: 0.9487\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2729 - accuracy: 0.8937 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2629 - accuracy: 0.8908 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2590 - accuracy: 0.8937 - val_loss: 0.2070 - val_accuracy: 0.9487\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2674 - accuracy: 0.8908 - val_loss: 0.2060 - val_accuracy: 0.9487\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2692 - accuracy: 0.8937 - val_loss: 0.2062 - val_accuracy: 0.9487\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2735 - accuracy: 0.8908 - val_loss: 0.2078 - val_accuracy: 0.9487\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2615 - accuracy: 0.8937 - val_loss: 0.2077 - val_accuracy: 0.9487\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.2576 - accuracy: 0.8937 - val_loss: 0.2090 - val_accuracy: 0.9487\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2745 - accuracy: 0.8908 - val_loss: 0.2091 - val_accuracy: 0.9487\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2671 - accuracy: 0.8937 - val_loss: 0.2049 - val_accuracy: 0.9487\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2580 - accuracy: 0.8908 - val_loss: 0.2051 - val_accuracy: 0.9487\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2614 - accuracy: 0.8937 - val_loss: 0.2067 - val_accuracy: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2710 - accuracy: 0.8937 - val_loss: 0.2082 - val_accuracy: 0.9487\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2638 - accuracy: 0.8908 - val_loss: 0.2113 - val_accuracy: 0.9487\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.2583 - accuracy: 0.8937 - val_loss: 0.2134 - val_accuracy: 0.9487\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2567 - accuracy: 0.8937 - val_loss: 0.2135 - val_accuracy: 0.9487\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2617 - accuracy: 0.8908 - val_loss: 0.2105 - val_accuracy: 0.9487\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2595 - accuracy: 0.8937 - val_loss: 0.2106 - val_accuracy: 0.9487\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2629 - accuracy: 0.8908 - val_loss: 0.2093 - val_accuracy: 0.9487\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2727 - accuracy: 0.8908 - val_loss: 0.2128 - val_accuracy: 0.9487\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2668 - accuracy: 0.8908 - val_loss: 0.2126 - val_accuracy: 0.9487\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2627 - accuracy: 0.8937 - val_loss: 0.2124 - val_accuracy: 0.9487\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2607 - accuracy: 0.8908 - val_loss: 0.2089 - val_accuracy: 0.9487\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2609 - accuracy: 0.8908 - val_loss: 0.2051 - val_accuracy: 0.9487\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2660 - accuracy: 0.8908 - val_loss: 0.2072 - val_accuracy: 0.9487\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2663 - accuracy: 0.8908 - val_loss: 0.2070 - val_accuracy: 0.9487\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2557 - accuracy: 0.8908 - val_loss: 0.2084 - val_accuracy: 0.9487\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2622 - accuracy: 0.8937 - val_loss: 0.2151 - val_accuracy: 0.9487\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2656 - accuracy: 0.8908 - val_loss: 0.2116 - val_accuracy: 0.9487\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2596 - accuracy: 0.8908 - val_loss: 0.2088 - val_accuracy: 0.9487\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2594 - accuracy: 0.8937 - val_loss: 0.2121 - val_accuracy: 0.9487\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2582 - accuracy: 0.8937 - val_loss: 0.2110 - val_accuracy: 0.9487\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2638 - accuracy: 0.8937 - val_loss: 0.2085 - val_accuracy: 0.9487\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2534 - accuracy: 0.8937 - val_loss: 0.2117 - val_accuracy: 0.9487\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2644 - accuracy: 0.8879 - val_loss: 0.2079 - val_accuracy: 0.9487\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2607 - accuracy: 0.8937 - val_loss: 0.2087 - val_accuracy: 0.9487\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2462 - accuracy: 0.8937 - val_loss: 0.2131 - val_accuracy: 0.9487\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2566 - accuracy: 0.8908 - val_loss: 0.2141 - val_accuracy: 0.9487\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2480 - accuracy: 0.8937 - val_loss: 0.2141 - val_accuracy: 0.9487\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2589 - accuracy: 0.8908 - val_loss: 0.2149 - val_accuracy: 0.9487\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2658 - accuracy: 0.8937 - val_loss: 0.2136 - val_accuracy: 0.9487\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2518 - accuracy: 0.8937 - val_loss: 0.2118 - val_accuracy: 0.9487\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2673 - accuracy: 0.8937 - val_loss: 0.2074 - val_accuracy: 0.9487\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2521 - accuracy: 0.8937 - val_loss: 0.2128 - val_accuracy: 0.9487\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2527 - accuracy: 0.8908 - val_loss: 0.2131 - val_accuracy: 0.9487\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2530 - accuracy: 0.8908 - val_loss: 0.2088 - val_accuracy: 0.9487\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2595 - accuracy: 0.8908 - val_loss: 0.2082 - val_accuracy: 0.9487\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2658 - accuracy: 0.8908 - val_loss: 0.2104 - val_accuracy: 0.9487\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2547 - accuracy: 0.8937 - val_loss: 0.2099 - val_accuracy: 0.9487\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2530 - accuracy: 0.8937 - val_loss: 0.2140 - val_accuracy: 0.9487\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2546 - accuracy: 0.8908 - val_loss: 0.2144 - val_accuracy: 0.9487\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2566 - accuracy: 0.8937 - val_loss: 0.2146 - val_accuracy: 0.9487\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2488 - accuracy: 0.8937 - val_loss: 0.2154 - val_accuracy: 0.9487\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2518 - accuracy: 0.8966 - val_loss: 0.2152 - val_accuracy: 0.9487\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2535 - accuracy: 0.8937 - val_loss: 0.2137 - val_accuracy: 0.9487\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2551 - accuracy: 0.8937 - val_loss: 0.2162 - val_accuracy: 0.9487\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2440 - accuracy: 0.8937 - val_loss: 0.2164 - val_accuracy: 0.9487\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2438 - accuracy: 0.8937 - val_loss: 0.2138 - val_accuracy: 0.9487\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2468 - accuracy: 0.8937 - val_loss: 0.2171 - val_accuracy: 0.9487\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2638 - accuracy: 0.8908 - val_loss: 0.2109 - val_accuracy: 0.9487\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2538 - accuracy: 0.8908 - val_loss: 0.2116 - val_accuracy: 0.9487\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.2509 - accuracy: 0.8937 - val_loss: 0.2144 - val_accuracy: 0.9487\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.2482 - accuracy: 0.8879 - val_loss: 0.2177 - val_accuracy: 0.9487\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2435 - accuracy: 0.8937 - val_loss: 0.2205 - val_accuracy: 0.9487\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2465 - accuracy: 0.8937 - val_loss: 0.2114 - val_accuracy: 0.9487\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2530 - accuracy: 0.8908 - val_loss: 0.2098 - val_accuracy: 0.9487\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2478 - accuracy: 0.8937 - val_loss: 0.2130 - val_accuracy: 0.9487\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2562 - accuracy: 0.8937 - val_loss: 0.2119 - val_accuracy: 0.9487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2418 - accuracy: 0.8937 - val_loss: 0.2153 - val_accuracy: 0.9487\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2541 - accuracy: 0.8908 - val_loss: 0.2182 - val_accuracy: 0.9487\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2534 - accuracy: 0.8937 - val_loss: 0.2133 - val_accuracy: 0.9487\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2503 - accuracy: 0.8937 - val_loss: 0.2166 - val_accuracy: 0.9487\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.2462 - accuracy: 0.8908 - val_loss: 0.2143 - val_accuracy: 0.9487\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.2458 - accuracy: 0.8908 - val_loss: 0.2142 - val_accuracy: 0.9487\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 129us/step - loss: 0.2510 - accuracy: 0.8908 - val_loss: 0.2197 - val_accuracy: 0.9487\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 141us/step - loss: 0.2542 - accuracy: 0.8908 - val_loss: 0.2124 - val_accuracy: 0.9487\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.2512 - accuracy: 0.8908 - val_loss: 0.2146 - val_accuracy: 0.9487\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 152us/step - loss: 0.2446 - accuracy: 0.8937 - val_loss: 0.2109 - val_accuracy: 0.9487\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.2652 - accuracy: 0.8908 - val_loss: 0.2141 - val_accuracy: 0.9487\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.2406 - accuracy: 0.8966 - val_loss: 0.2170 - val_accuracy: 0.9487\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2451 - accuracy: 0.8937 - val_loss: 0.2202 - val_accuracy: 0.9487\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2489 - accuracy: 0.8937 - val_loss: 0.2217 - val_accuracy: 0.9487\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.2509 - accuracy: 0.8908 - val_loss: 0.2180 - val_accuracy: 0.9487\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2484 - accuracy: 0.8908 - val_loss: 0.2158 - val_accuracy: 0.9487\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2518 - accuracy: 0.8937 - val_loss: 0.2142 - val_accuracy: 0.9487\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2446 - accuracy: 0.8908 - val_loss: 0.2174 - val_accuracy: 0.9487\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2582 - accuracy: 0.8937 - val_loss: 0.2158 - val_accuracy: 0.9487\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2477 - accuracy: 0.8937 - val_loss: 0.2156 - val_accuracy: 0.9487\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2489 - accuracy: 0.8879 - val_loss: 0.2175 - val_accuracy: 0.9487\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.2521 - accuracy: 0.8908 - val_loss: 0.2210 - val_accuracy: 0.9487\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2540 - accuracy: 0.8879 - val_loss: 0.2233 - val_accuracy: 0.9487\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2380 - accuracy: 0.8937 - val_loss: 0.2240 - val_accuracy: 0.9487\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2347 - accuracy: 0.8908 - val_loss: 0.2207 - val_accuracy: 0.9487\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2480 - accuracy: 0.8937 - val_loss: 0.2206 - val_accuracy: 0.9487\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2443 - accuracy: 0.8908 - val_loss: 0.2222 - val_accuracy: 0.9487\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2529 - accuracy: 0.8908 - val_loss: 0.2190 - val_accuracy: 0.9487\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2470 - accuracy: 0.8937 - val_loss: 0.2189 - val_accuracy: 0.9487\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2524 - accuracy: 0.8937 - val_loss: 0.2138 - val_accuracy: 0.9487\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2418 - accuracy: 0.8937 - val_loss: 0.2135 - val_accuracy: 0.9487\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2508 - accuracy: 0.8937 - val_loss: 0.2143 - val_accuracy: 0.9487\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2478 - accuracy: 0.8937 - val_loss: 0.2204 - val_accuracy: 0.9487\n",
      "Predicted: [[1.0693073e-04]\n",
      " [1.0981801e-01]\n",
      " [3.7059188e-04]\n",
      " [3.7249923e-04]\n",
      " [1.6653538e-04]\n",
      " [2.0154834e-02]\n",
      " [2.5715956e-01]\n",
      " [5.7363510e-04]\n",
      " [5.1207751e-02]\n",
      " [2.1118313e-02]\n",
      " [1.1987522e-01]\n",
      " [3.0293685e-01]\n",
      " [3.2280868e-01]\n",
      " [9.8984092e-02]\n",
      " [1.5464199e-01]\n",
      " [2.6835552e-01]\n",
      " [3.1991243e-01]\n",
      " [2.9374996e-01]\n",
      " [3.4363055e-01]\n",
      " [2.2113323e-05]\n",
      " [2.9259777e-01]\n",
      " [2.8192997e-05]\n",
      " [3.5172284e-01]\n",
      " [5.6363136e-02]\n",
      " [1.5885282e-01]\n",
      " [8.4267229e-02]\n",
      " [3.6045870e-01]\n",
      " [6.7412853e-05]\n",
      " [6.6584349e-04]\n",
      " [3.2954714e-01]\n",
      " [1.4877319e-04]\n",
      " [2.6822090e-07]\n",
      " [3.0412525e-01]\n",
      " [2.9523575e-01]\n",
      " [8.4519058e-02]\n",
      " [4.3142945e-02]\n",
      " [8.0566853e-02]\n",
      " [1.1712313e-05]\n",
      " [3.6627054e-05]\n",
      " [1.6766787e-04]\n",
      " [9.2546418e-02]\n",
      " [4.3079838e-02]\n",
      " [1.0135760e-02]]\n",
      "Actual: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "43/43 [==============================] - 0s 93us/step\n",
      "Eval: [0.27686340587083685, 0.9069767594337463]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6693 - accuracy: 0.6523 - val_loss: 0.6375 - val_accuracy: 0.7179\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5972 - accuracy: 0.7644 - val_loss: 0.5956 - val_accuracy: 0.7179\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.5461 - accuracy: 0.7701 - val_loss: 0.6021 - val_accuracy: 0.7179\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5762 - accuracy: 0.7701 - val_loss: 0.5770 - val_accuracy: 0.7179\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5404 - accuracy: 0.7701 - val_loss: 0.5702 - val_accuracy: 0.7179\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.5390 - accuracy: 0.7701 - val_loss: 0.5554 - val_accuracy: 0.7179\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5358 - accuracy: 0.7701 - val_loss: 0.5457 - val_accuracy: 0.7179\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5174 - accuracy: 0.7701 - val_loss: 0.5441 - val_accuracy: 0.7179\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.5097 - accuracy: 0.7701 - val_loss: 0.5412 - val_accuracy: 0.7179\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.5104 - accuracy: 0.7701 - val_loss: 0.5261 - val_accuracy: 0.7179\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.5094 - accuracy: 0.7759 - val_loss: 0.5178 - val_accuracy: 0.7179\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4864 - accuracy: 0.7701 - val_loss: 0.5279 - val_accuracy: 0.7179\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4895 - accuracy: 0.7701 - val_loss: 0.5212 - val_accuracy: 0.7179\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4982 - accuracy: 0.7730 - val_loss: 0.5054 - val_accuracy: 0.7179\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4878 - accuracy: 0.7759 - val_loss: 0.5049 - val_accuracy: 0.7179\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4754 - accuracy: 0.7845 - val_loss: 0.4959 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4650 - accuracy: 0.7816 - val_loss: 0.5106 - val_accuracy: 0.7179\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4538 - accuracy: 0.7787 - val_loss: 0.5053 - val_accuracy: 0.7179\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4654 - accuracy: 0.7874 - val_loss: 0.4908 - val_accuracy: 0.7179\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4664 - accuracy: 0.7960 - val_loss: 0.4922 - val_accuracy: 0.6923\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4565 - accuracy: 0.7989 - val_loss: 0.5076 - val_accuracy: 0.6923\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4511 - accuracy: 0.7931 - val_loss: 0.5167 - val_accuracy: 0.6923\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4630 - accuracy: 0.7816 - val_loss: 0.5369 - val_accuracy: 0.6923\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4730 - accuracy: 0.7989 - val_loss: 0.5049 - val_accuracy: 0.7179\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4521 - accuracy: 0.8190 - val_loss: 0.5497 - val_accuracy: 0.6923\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4598 - accuracy: 0.7787 - val_loss: 0.5469 - val_accuracy: 0.6923\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4496 - accuracy: 0.7989 - val_loss: 0.5098 - val_accuracy: 0.7179\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4500 - accuracy: 0.8305 - val_loss: 0.5521 - val_accuracy: 0.6923\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4380 - accuracy: 0.8046 - val_loss: 0.5068 - val_accuracy: 0.7179\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4367 - accuracy: 0.7874 - val_loss: 0.5271 - val_accuracy: 0.7179\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4397 - accuracy: 0.8103 - val_loss: 0.5266 - val_accuracy: 0.7179\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4446 - accuracy: 0.8247 - val_loss: 0.5245 - val_accuracy: 0.7179\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.4462 - accuracy: 0.8075 - val_loss: 0.5273 - val_accuracy: 0.7179\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.4426 - accuracy: 0.7931 - val_loss: 0.5333 - val_accuracy: 0.6923\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4505 - accuracy: 0.8017 - val_loss: 0.5344 - val_accuracy: 0.6923\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4396 - accuracy: 0.8218 - val_loss: 0.5369 - val_accuracy: 0.6923\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4429 - accuracy: 0.7960 - val_loss: 0.5383 - val_accuracy: 0.6923\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4336 - accuracy: 0.7989 - val_loss: 0.5449 - val_accuracy: 0.6923\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4339 - accuracy: 0.8046 - val_loss: 0.5601 - val_accuracy: 0.6923\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4335 - accuracy: 0.8046 - val_loss: 0.5346 - val_accuracy: 0.7179\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4207 - accuracy: 0.8190 - val_loss: 0.5277 - val_accuracy: 0.7436\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4261 - accuracy: 0.8017 - val_loss: 0.5571 - val_accuracy: 0.6923\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4194 - accuracy: 0.8103 - val_loss: 0.5164 - val_accuracy: 0.7436\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 127us/step - loss: 0.4294 - accuracy: 0.7931 - val_loss: 0.5309 - val_accuracy: 0.7179\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.4103 - accuracy: 0.8161 - val_loss: 0.5498 - val_accuracy: 0.6923\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4272 - accuracy: 0.8046 - val_loss: 0.5346 - val_accuracy: 0.7436\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4260 - accuracy: 0.8046 - val_loss: 0.5495 - val_accuracy: 0.7179\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4161 - accuracy: 0.8017 - val_loss: 0.5425 - val_accuracy: 0.7436\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4261 - accuracy: 0.7989 - val_loss: 0.5439 - val_accuracy: 0.7179\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4257 - accuracy: 0.8103 - val_loss: 0.5326 - val_accuracy: 0.7436\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4141 - accuracy: 0.8132 - val_loss: 0.5547 - val_accuracy: 0.7179\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4215 - accuracy: 0.8161 - val_loss: 0.5631 - val_accuracy: 0.6923\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4173 - accuracy: 0.8276 - val_loss: 0.5362 - val_accuracy: 0.7436\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4414 - accuracy: 0.7931 - val_loss: 0.5631 - val_accuracy: 0.6923\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4158 - accuracy: 0.8161 - val_loss: 0.5580 - val_accuracy: 0.6923\n",
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4363 - accuracy: 0.7874 - val_loss: 0.5364 - val_accuracy: 0.7436\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4090 - accuracy: 0.8132 - val_loss: 0.5494 - val_accuracy: 0.7436\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4074 - accuracy: 0.8305 - val_loss: 0.5563 - val_accuracy: 0.7179\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4182 - accuracy: 0.7874 - val_loss: 0.5211 - val_accuracy: 0.7436\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4342 - accuracy: 0.8017 - val_loss: 0.5697 - val_accuracy: 0.7179\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4237 - accuracy: 0.8132 - val_loss: 0.5514 - val_accuracy: 0.7436\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4149 - accuracy: 0.8103 - val_loss: 0.5526 - val_accuracy: 0.7436\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4180 - accuracy: 0.8046 - val_loss: 0.5488 - val_accuracy: 0.7179\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4157 - accuracy: 0.8103 - val_loss: 0.5426 - val_accuracy: 0.7436\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4107 - accuracy: 0.8218 - val_loss: 0.5703 - val_accuracy: 0.7179\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4081 - accuracy: 0.8017 - val_loss: 0.5657 - val_accuracy: 0.7179\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4269 - accuracy: 0.7989 - val_loss: 0.5294 - val_accuracy: 0.7436\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4220 - accuracy: 0.7989 - val_loss: 0.5473 - val_accuracy: 0.7179\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4162 - accuracy: 0.8103 - val_loss: 0.5688 - val_accuracy: 0.7179\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4043 - accuracy: 0.8276 - val_loss: 0.5574 - val_accuracy: 0.6923\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4163 - accuracy: 0.8161 - val_loss: 0.5558 - val_accuracy: 0.6923\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4101 - accuracy: 0.8190 - val_loss: 0.5573 - val_accuracy: 0.7179\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 104us/step - loss: 0.4051 - accuracy: 0.8190 - val_loss: 0.5512 - val_accuracy: 0.7436\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3889 - accuracy: 0.8362 - val_loss: 0.5693 - val_accuracy: 0.7436\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4210 - accuracy: 0.8161 - val_loss: 0.5785 - val_accuracy: 0.7436\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4036 - accuracy: 0.8103 - val_loss: 0.5719 - val_accuracy: 0.7436\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3985 - accuracy: 0.8132 - val_loss: 0.5795 - val_accuracy: 0.7179\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3979 - accuracy: 0.7960 - val_loss: 0.5563 - val_accuracy: 0.7436\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4235 - accuracy: 0.8161 - val_loss: 0.5693 - val_accuracy: 0.7179\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4138 - accuracy: 0.8218 - val_loss: 0.6018 - val_accuracy: 0.6923\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4135 - accuracy: 0.7902 - val_loss: 0.5510 - val_accuracy: 0.7436\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4104 - accuracy: 0.8103 - val_loss: 0.5586 - val_accuracy: 0.7436\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 604us/step - loss: 0.4137 - accuracy: 0.8075 - val_loss: 0.5495 - val_accuracy: 0.7436\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4100 - accuracy: 0.8247 - val_loss: 0.5925 - val_accuracy: 0.6923\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3937 - accuracy: 0.8103 - val_loss: 0.5503 - val_accuracy: 0.7436\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3941 - accuracy: 0.8247 - val_loss: 0.5681 - val_accuracy: 0.7436\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4166 - accuracy: 0.8161 - val_loss: 0.5545 - val_accuracy: 0.7436\n",
      "Epoch 88/200\n",
      " 32/348 [=>............................] - ETA: 0s - loss: 0.2832 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.152107). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 101us/step - loss: 0.3874 - accuracy: 0.8305 - val_loss: 0.5813 - val_accuracy: 0.7179\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3938 - accuracy: 0.8333 - val_loss: 0.5614 - val_accuracy: 0.7436\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3995 - accuracy: 0.8132 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4003 - accuracy: 0.8017 - val_loss: 0.6005 - val_accuracy: 0.7436\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3907 - accuracy: 0.8276 - val_loss: 0.5785 - val_accuracy: 0.7436\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.87 - 0s 95us/step - loss: 0.3923 - accuracy: 0.8276 - val_loss: 0.5747 - val_accuracy: 0.7436\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4052 - accuracy: 0.7989 - val_loss: 0.5794 - val_accuracy: 0.7436\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4106 - accuracy: 0.8161 - val_loss: 0.5592 - val_accuracy: 0.7436\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4170 - accuracy: 0.7931 - val_loss: 0.5587 - val_accuracy: 0.7436\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4074 - accuracy: 0.8276 - val_loss: 0.5557 - val_accuracy: 0.6923\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4047 - accuracy: 0.8161 - val_loss: 0.5755 - val_accuracy: 0.6923\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3781 - accuracy: 0.8305 - val_loss: 0.5693 - val_accuracy: 0.7436\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3996 - accuracy: 0.8218 - val_loss: 0.5607 - val_accuracy: 0.7436\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3997 - accuracy: 0.8161 - val_loss: 0.5967 - val_accuracy: 0.6923\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3730 - accuracy: 0.8506 - val_loss: 0.5901 - val_accuracy: 0.7436\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3809 - accuracy: 0.8333 - val_loss: 0.5781 - val_accuracy: 0.7436\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3903 - accuracy: 0.8190 - val_loss: 0.5537 - val_accuracy: 0.7436\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4014 - accuracy: 0.8103 - val_loss: 0.6134 - val_accuracy: 0.7436\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4024 - accuracy: 0.8075 - val_loss: 0.5715 - val_accuracy: 0.7436\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3656 - accuracy: 0.8362 - val_loss: 0.5832 - val_accuracy: 0.7436\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4011 - accuracy: 0.8103 - val_loss: 0.5747 - val_accuracy: 0.7436\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4039 - accuracy: 0.8075 - val_loss: 0.5748 - val_accuracy: 0.7436\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3731 - accuracy: 0.8190 - val_loss: 0.5592 - val_accuracy: 0.7436\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4005 - accuracy: 0.8218 - val_loss: 0.5929 - val_accuracy: 0.6923\n",
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3877 - accuracy: 0.8161 - val_loss: 0.5699 - val_accuracy: 0.7436\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3973 - accuracy: 0.8190 - val_loss: 0.5893 - val_accuracy: 0.7436\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3890 - accuracy: 0.8247 - val_loss: 0.5613 - val_accuracy: 0.7436\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4008 - accuracy: 0.8247 - val_loss: 0.5538 - val_accuracy: 0.7436\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3837 - accuracy: 0.8305 - val_loss: 0.5364 - val_accuracy: 0.7436\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3942 - accuracy: 0.8190 - val_loss: 0.5694 - val_accuracy: 0.7436\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.5934 - val_accuracy: 0.7179\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3808 - accuracy: 0.8362 - val_loss: 0.5717 - val_accuracy: 0.7436\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4022 - accuracy: 0.8132 - val_loss: 0.5617 - val_accuracy: 0.7436\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4012 - accuracy: 0.8218 - val_loss: 0.5764 - val_accuracy: 0.7436\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3711 - accuracy: 0.8448 - val_loss: 0.5640 - val_accuracy: 0.7436\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.3780 - accuracy: 0.8046 - val_loss: 0.5639 - val_accuracy: 0.7436\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3734 - accuracy: 0.8276 - val_loss: 0.5564 - val_accuracy: 0.7436\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3992 - accuracy: 0.8218 - val_loss: 0.5734 - val_accuracy: 0.7436\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.3888 - accuracy: 0.8132 - val_loss: 0.6077 - val_accuracy: 0.6923\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3876 - accuracy: 0.8132 - val_loss: 0.5730 - val_accuracy: 0.7436\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3839 - accuracy: 0.8218 - val_loss: 0.5609 - val_accuracy: 0.7692\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3849 - accuracy: 0.8276 - val_loss: 0.5933 - val_accuracy: 0.7436\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3911 - accuracy: 0.8218 - val_loss: 0.5681 - val_accuracy: 0.7436\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3931 - accuracy: 0.8362 - val_loss: 0.5889 - val_accuracy: 0.7436\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3964 - accuracy: 0.8046 - val_loss: 0.5723 - val_accuracy: 0.7436\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3797 - accuracy: 0.8276 - val_loss: 0.6092 - val_accuracy: 0.7436\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3898 - accuracy: 0.8132 - val_loss: 0.5863 - val_accuracy: 0.7436\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3888 - accuracy: 0.8190 - val_loss: 0.5855 - val_accuracy: 0.7436\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3848 - accuracy: 0.8103 - val_loss: 0.5936 - val_accuracy: 0.7436\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3684 - accuracy: 0.8218 - val_loss: 0.6183 - val_accuracy: 0.6923\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3763 - accuracy: 0.8218 - val_loss: 0.5826 - val_accuracy: 0.7436\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3782 - accuracy: 0.8276 - val_loss: 0.5658 - val_accuracy: 0.7436\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3747 - accuracy: 0.8276 - val_loss: 0.6023 - val_accuracy: 0.7179\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3706 - accuracy: 0.8362 - val_loss: 0.5659 - val_accuracy: 0.7692\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3841 - accuracy: 0.8161 - val_loss: 0.5901 - val_accuracy: 0.7436\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3688 - accuracy: 0.8161 - val_loss: 0.5806 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3790 - accuracy: 0.8190 - val_loss: 0.5942 - val_accuracy: 0.7436\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3912 - accuracy: 0.8075 - val_loss: 0.5975 - val_accuracy: 0.7436\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3696 - accuracy: 0.8448 - val_loss: 0.5500 - val_accuracy: 0.7692\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3814 - accuracy: 0.8333 - val_loss: 0.6007 - val_accuracy: 0.7436\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3657 - accuracy: 0.8362 - val_loss: 0.5944 - val_accuracy: 0.7436\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3803 - accuracy: 0.8132 - val_loss: 0.5638 - val_accuracy: 0.7692\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3854 - accuracy: 0.8247 - val_loss: 0.5718 - val_accuracy: 0.7436\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3847 - accuracy: 0.8276 - val_loss: 0.5987 - val_accuracy: 0.7179\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5569 - val_accuracy: 0.7436\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3662 - accuracy: 0.8391 - val_loss: 0.5639 - val_accuracy: 0.7436\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3764 - accuracy: 0.8247 - val_loss: 0.5998 - val_accuracy: 0.7436\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3852 - accuracy: 0.8276 - val_loss: 0.5747 - val_accuracy: 0.7436\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3868 - accuracy: 0.8333 - val_loss: 0.5940 - val_accuracy: 0.7436\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3707 - accuracy: 0.8190 - val_loss: 0.5827 - val_accuracy: 0.7436\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3688 - accuracy: 0.8362 - val_loss: 0.5850 - val_accuracy: 0.7692\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3646 - accuracy: 0.8333 - val_loss: 0.6281 - val_accuracy: 0.7436\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3760 - accuracy: 0.8448 - val_loss: 0.5920 - val_accuracy: 0.7436\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3651 - accuracy: 0.8333 - val_loss: 0.6227 - val_accuracy: 0.7436\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3621 - accuracy: 0.8333 - val_loss: 0.5888 - val_accuracy: 0.7692\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3727 - accuracy: 0.8448 - val_loss: 0.5985 - val_accuracy: 0.7692\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3677 - accuracy: 0.8333 - val_loss: 0.6205 - val_accuracy: 0.7436\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3617 - accuracy: 0.8276 - val_loss: 0.6307 - val_accuracy: 0.7179\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3795 - accuracy: 0.8247 - val_loss: 0.5800 - val_accuracy: 0.7436\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3607 - accuracy: 0.8448 - val_loss: 0.5810 - val_accuracy: 0.7436\n",
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3834 - accuracy: 0.8333 - val_loss: 0.6030 - val_accuracy: 0.7436\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3730 - accuracy: 0.8190 - val_loss: 0.5829 - val_accuracy: 0.7436\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3623 - accuracy: 0.8276 - val_loss: 0.5898 - val_accuracy: 0.7436\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3837 - accuracy: 0.8333 - val_loss: 0.6025 - val_accuracy: 0.7436\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3676 - accuracy: 0.8276 - val_loss: 0.6014 - val_accuracy: 0.7436\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3767 - accuracy: 0.8190 - val_loss: 0.6040 - val_accuracy: 0.7436\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3619 - accuracy: 0.8391 - val_loss: 0.5791 - val_accuracy: 0.7436\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3707 - accuracy: 0.8276 - val_loss: 0.6081 - val_accuracy: 0.7179\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3768 - accuracy: 0.8247 - val_loss: 0.6195 - val_accuracy: 0.7179\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3742 - accuracy: 0.8305 - val_loss: 0.5835 - val_accuracy: 0.7436\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3712 - accuracy: 0.8448 - val_loss: 0.5876 - val_accuracy: 0.7436\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3692 - accuracy: 0.8333 - val_loss: 0.5812 - val_accuracy: 0.7436\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3741 - accuracy: 0.8420 - val_loss: 0.5959 - val_accuracy: 0.7179\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3769 - accuracy: 0.8190 - val_loss: 0.5917 - val_accuracy: 0.7436\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3637 - accuracy: 0.8276 - val_loss: 0.6042 - val_accuracy: 0.7179\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3776 - accuracy: 0.8362 - val_loss: 0.5936 - val_accuracy: 0.7179\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3688 - accuracy: 0.8276 - val_loss: 0.5989 - val_accuracy: 0.7436\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3756 - accuracy: 0.8247 - val_loss: 0.5922 - val_accuracy: 0.7436\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3772 - accuracy: 0.8276 - val_loss: 0.6170 - val_accuracy: 0.7179\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3661 - accuracy: 0.8276 - val_loss: 0.6388 - val_accuracy: 0.6923\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3785 - accuracy: 0.8477 - val_loss: 0.5909 - val_accuracy: 0.7436\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3839 - accuracy: 0.8305 - val_loss: 0.5990 - val_accuracy: 0.7436\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3724 - accuracy: 0.8103 - val_loss: 0.6048 - val_accuracy: 0.7179\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3759 - accuracy: 0.8190 - val_loss: 0.5952 - val_accuracy: 0.7436\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3620 - accuracy: 0.8333 - val_loss: 0.6110 - val_accuracy: 0.7436\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3707 - accuracy: 0.8333 - val_loss: 0.6016 - val_accuracy: 0.7436\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3662 - accuracy: 0.8305 - val_loss: 0.6211 - val_accuracy: 0.7436\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3687 - accuracy: 0.8075 - val_loss: 0.6417 - val_accuracy: 0.7436\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3738 - accuracy: 0.8362 - val_loss: 0.6247 - val_accuracy: 0.7436\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3683 - accuracy: 0.8362 - val_loss: 0.6075 - val_accuracy: 0.7436\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.3610 - accuracy: 0.8448 - val_loss: 0.6481 - val_accuracy: 0.7179\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3607 - accuracy: 0.8305 - val_loss: 0.6100 - val_accuracy: 0.7436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.3592 - accuracy: 0.8362 - val_loss: 0.6076 - val_accuracy: 0.7436\n",
      "Predicted: [[0.00293571]\n",
      " [0.19647115]\n",
      " [0.04019126]\n",
      " [0.147638  ]\n",
      " [0.7112628 ]\n",
      " [0.00640076]\n",
      " [0.32510227]\n",
      " [0.01932681]\n",
      " [0.28565294]\n",
      " [0.00671583]\n",
      " [0.55058056]\n",
      " [0.12496826]\n",
      " [0.21797377]\n",
      " [0.07680479]\n",
      " [0.03365058]\n",
      " [0.18251649]\n",
      " [0.05595669]\n",
      " [0.459473  ]\n",
      " [0.31382674]\n",
      " [0.49348703]\n",
      " [0.29879552]\n",
      " [0.01949108]\n",
      " [0.01014081]\n",
      " [0.18236631]\n",
      " [0.08387777]\n",
      " [0.01842874]\n",
      " [0.05542174]\n",
      " [0.01414868]\n",
      " [0.2159757 ]\n",
      " [0.11607981]\n",
      " [0.18927476]\n",
      " [0.05771786]\n",
      " [0.5675661 ]\n",
      " [0.17541072]\n",
      " [0.03488952]\n",
      " [0.22976774]\n",
      " [0.12254611]\n",
      " [0.02516705]\n",
      " [0.15852526]\n",
      " [0.03699911]\n",
      " [0.03464497]\n",
      " [0.05084254]\n",
      " [0.07548124]]\n",
      "Actual: [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "43/43 [==============================] - 0s 70us/step\n",
      "Eval: [0.3708365885324256, 0.8139534592628479]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 880us/step - loss: 0.6968 - accuracy: 0.5115 - val_loss: 0.6735 - val_accuracy: 0.6923\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.6532 - accuracy: 0.7069 - val_loss: 0.6270 - val_accuracy: 0.6923\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.6093 - accuracy: 0.7040 - val_loss: 0.5904 - val_accuracy: 0.6923\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 81us/step - loss: 0.5836 - accuracy: 0.7040 - val_loss: 0.5714 - val_accuracy: 0.6923\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 81us/step - loss: 0.5659 - accuracy: 0.7040 - val_loss: 0.5479 - val_accuracy: 0.6923\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5503 - accuracy: 0.7040 - val_loss: 0.5228 - val_accuracy: 0.6923\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 81us/step - loss: 0.5510 - accuracy: 0.6983 - val_loss: 0.5106 - val_accuracy: 0.6923\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5326 - accuracy: 0.7040 - val_loss: 0.5022 - val_accuracy: 0.6923\n",
      "Epoch 9/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5268 - accuracy: 0.7241 - val_loss: 0.4992 - val_accuracy: 0.6923\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.5328 - accuracy: 0.7040 - val_loss: 0.5019 - val_accuracy: 0.6923\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5146 - accuracy: 0.7040 - val_loss: 0.4956 - val_accuracy: 0.6923\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.5175 - accuracy: 0.7040 - val_loss: 0.4896 - val_accuracy: 0.6923\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.5118 - accuracy: 0.7155 - val_loss: 0.4853 - val_accuracy: 0.7692\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5134 - accuracy: 0.7011 - val_loss: 0.4842 - val_accuracy: 0.7692\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.5015 - accuracy: 0.7471 - val_loss: 0.4860 - val_accuracy: 0.7692\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4948 - accuracy: 0.7356 - val_loss: 0.4813 - val_accuracy: 0.7949\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.5091 - accuracy: 0.7471 - val_loss: 0.4816 - val_accuracy: 0.7692\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4976 - accuracy: 0.7414 - val_loss: 0.4788 - val_accuracy: 0.7692\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4911 - accuracy: 0.7557 - val_loss: 0.4736 - val_accuracy: 0.7692\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4932 - accuracy: 0.7586 - val_loss: 0.4719 - val_accuracy: 0.7692\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4954 - accuracy: 0.7443 - val_loss: 0.4729 - val_accuracy: 0.7692\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4806 - accuracy: 0.7615 - val_loss: 0.4716 - val_accuracy: 0.7949\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4897 - accuracy: 0.7500 - val_loss: 0.4704 - val_accuracy: 0.7949\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4762 - accuracy: 0.7586 - val_loss: 0.4698 - val_accuracy: 0.8205\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4743 - accuracy: 0.7356 - val_loss: 0.4694 - val_accuracy: 0.8205\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4878 - accuracy: 0.7443 - val_loss: 0.4699 - val_accuracy: 0.8205\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4913 - accuracy: 0.7356 - val_loss: 0.4684 - val_accuracy: 0.7949\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4837 - accuracy: 0.7385 - val_loss: 0.4695 - val_accuracy: 0.7949\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4987 - accuracy: 0.7356 - val_loss: 0.4691 - val_accuracy: 0.8205\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4740 - accuracy: 0.7701 - val_loss: 0.4694 - val_accuracy: 0.8205\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4872 - accuracy: 0.7615 - val_loss: 0.4653 - val_accuracy: 0.8205\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4722 - accuracy: 0.7672 - val_loss: 0.4729 - val_accuracy: 0.7949\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4866 - accuracy: 0.7586 - val_loss: 0.4695 - val_accuracy: 0.7949\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4795 - accuracy: 0.7299 - val_loss: 0.4619 - val_accuracy: 0.8205\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.78 - 0s 101us/step - loss: 0.4744 - accuracy: 0.7500 - val_loss: 0.4654 - val_accuracy: 0.8205\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4754 - accuracy: 0.7385 - val_loss: 0.4643 - val_accuracy: 0.8205\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4735 - accuracy: 0.7529 - val_loss: 0.4663 - val_accuracy: 0.8205\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4784 - accuracy: 0.7414 - val_loss: 0.4615 - val_accuracy: 0.7949\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4813 - accuracy: 0.7615 - val_loss: 0.4707 - val_accuracy: 0.8205\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4778 - accuracy: 0.7615 - val_loss: 0.4637 - val_accuracy: 0.7949\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4804 - accuracy: 0.7385 - val_loss: 0.4613 - val_accuracy: 0.7949\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4824 - accuracy: 0.7500 - val_loss: 0.4644 - val_accuracy: 0.8205\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4632 - accuracy: 0.7672 - val_loss: 0.4710 - val_accuracy: 0.7692\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4745 - accuracy: 0.7385 - val_loss: 0.4647 - val_accuracy: 0.7949\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4707 - accuracy: 0.7701 - val_loss: 0.4645 - val_accuracy: 0.8205\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4569 - accuracy: 0.7644 - val_loss: 0.4692 - val_accuracy: 0.7692\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4689 - accuracy: 0.7759 - val_loss: 0.4666 - val_accuracy: 0.7949\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4626 - accuracy: 0.7615 - val_loss: 0.4653 - val_accuracy: 0.7692\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 106us/step - loss: 0.4575 - accuracy: 0.7644 - val_loss: 0.4617 - val_accuracy: 0.7949\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4531 - accuracy: 0.7730 - val_loss: 0.4646 - val_accuracy: 0.7692\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4526 - accuracy: 0.7557 - val_loss: 0.4645 - val_accuracy: 0.7949\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4615 - accuracy: 0.7557 - val_loss: 0.4617 - val_accuracy: 0.8205\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4604 - accuracy: 0.7672 - val_loss: 0.4667 - val_accuracy: 0.7692\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4584 - accuracy: 0.7557 - val_loss: 0.4670 - val_accuracy: 0.7692\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4379 - accuracy: 0.7615 - val_loss: 0.4665 - val_accuracy: 0.7949\n",
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4583 - accuracy: 0.7529 - val_loss: 0.4697 - val_accuracy: 0.7949\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4776 - accuracy: 0.7471 - val_loss: 0.4597 - val_accuracy: 0.7949\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4753 - accuracy: 0.7557 - val_loss: 0.4644 - val_accuracy: 0.7949\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4605 - accuracy: 0.7644 - val_loss: 0.4650 - val_accuracy: 0.7949\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4508 - accuracy: 0.7672 - val_loss: 0.4662 - val_accuracy: 0.7949\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4550 - accuracy: 0.7759 - val_loss: 0.4669 - val_accuracy: 0.7949\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4677 - accuracy: 0.7500 - val_loss: 0.4628 - val_accuracy: 0.7949\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4425 - accuracy: 0.7586 - val_loss: 0.4704 - val_accuracy: 0.7949\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4757 - accuracy: 0.7443 - val_loss: 0.4626 - val_accuracy: 0.7949\n",
      "Epoch 65/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4702 - accuracy: 0.7787 - val_loss: 0.4629 - val_accuracy: 0.7949\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4525 - accuracy: 0.7701 - val_loss: 0.4659 - val_accuracy: 0.7949\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4593 - accuracy: 0.7443 - val_loss: 0.4700 - val_accuracy: 0.7949\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4291 - accuracy: 0.7787 - val_loss: 0.4647 - val_accuracy: 0.7949\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4444 - accuracy: 0.7701 - val_loss: 0.4760 - val_accuracy: 0.7692\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4531 - accuracy: 0.7500 - val_loss: 0.4702 - val_accuracy: 0.7949\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4444 - accuracy: 0.7931 - val_loss: 0.4802 - val_accuracy: 0.7692\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4492 - accuracy: 0.7730 - val_loss: 0.4676 - val_accuracy: 0.7949\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4488 - accuracy: 0.7701 - val_loss: 0.4688 - val_accuracy: 0.8205\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4535 - accuracy: 0.7557 - val_loss: 0.4672 - val_accuracy: 0.7949\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4433 - accuracy: 0.7960 - val_loss: 0.4698 - val_accuracy: 0.7949\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4444 - accuracy: 0.7672 - val_loss: 0.4634 - val_accuracy: 0.7949\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4379 - accuracy: 0.7902 - val_loss: 0.4735 - val_accuracy: 0.8205\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4411 - accuracy: 0.7615 - val_loss: 0.4808 - val_accuracy: 0.8205\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4449 - accuracy: 0.7586 - val_loss: 0.4732 - val_accuracy: 0.7949\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4325 - accuracy: 0.7874 - val_loss: 0.4847 - val_accuracy: 0.7949\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4459 - accuracy: 0.7730 - val_loss: 0.4807 - val_accuracy: 0.7949\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4501 - accuracy: 0.7644 - val_loss: 0.4731 - val_accuracy: 0.7949\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4427 - accuracy: 0.7615 - val_loss: 0.4733 - val_accuracy: 0.7949\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4295 - accuracy: 0.7787 - val_loss: 0.4831 - val_accuracy: 0.7949\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4490 - accuracy: 0.7672 - val_loss: 0.4850 - val_accuracy: 0.7949\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4310 - accuracy: 0.7989 - val_loss: 0.4751 - val_accuracy: 0.7949\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4333 - accuracy: 0.7787 - val_loss: 0.4803 - val_accuracy: 0.7949\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4334 - accuracy: 0.7874 - val_loss: 0.4859 - val_accuracy: 0.7949\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4482 - accuracy: 0.7557 - val_loss: 0.4836 - val_accuracy: 0.7949\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4368 - accuracy: 0.7816 - val_loss: 0.4909 - val_accuracy: 0.7949\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4344 - accuracy: 0.7787 - val_loss: 0.4890 - val_accuracy: 0.7949\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4503 - accuracy: 0.7443 - val_loss: 0.4852 - val_accuracy: 0.7949\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4414 - accuracy: 0.7586 - val_loss: 0.4842 - val_accuracy: 0.7949\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4207 - accuracy: 0.7730 - val_loss: 0.4846 - val_accuracy: 0.7949\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4378 - accuracy: 0.7644 - val_loss: 0.4910 - val_accuracy: 0.8205\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4357 - accuracy: 0.7701 - val_loss: 0.4855 - val_accuracy: 0.7949\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4222 - accuracy: 0.7902 - val_loss: 0.4971 - val_accuracy: 0.7949\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4328 - accuracy: 0.7730 - val_loss: 0.4851 - val_accuracy: 0.7949\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4401 - accuracy: 0.7787 - val_loss: 0.4934 - val_accuracy: 0.7949\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4301 - accuracy: 0.7845 - val_loss: 0.5028 - val_accuracy: 0.7949\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4371 - accuracy: 0.7787 - val_loss: 0.4967 - val_accuracy: 0.7949\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4364 - accuracy: 0.7644 - val_loss: 0.4930 - val_accuracy: 0.7949\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4307 - accuracy: 0.7787 - val_loss: 0.4957 - val_accuracy: 0.8205\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4220 - accuracy: 0.7759 - val_loss: 0.4998 - val_accuracy: 0.7949\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 112us/step - loss: 0.4410 - accuracy: 0.7845 - val_loss: 0.4945 - val_accuracy: 0.7949\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4370 - accuracy: 0.7787 - val_loss: 0.4894 - val_accuracy: 0.7949\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 129us/step - loss: 0.4293 - accuracy: 0.7759 - val_loss: 0.4982 - val_accuracy: 0.8205\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4374 - accuracy: 0.7845 - val_loss: 0.4920 - val_accuracy: 0.7949\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4351 - accuracy: 0.7730 - val_loss: 0.4939 - val_accuracy: 0.7949\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4363 - accuracy: 0.7787 - val_loss: 0.4942 - val_accuracy: 0.7949\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4474 - accuracy: 0.7845 - val_loss: 0.4993 - val_accuracy: 0.8205\n",
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4177 - accuracy: 0.7672 - val_loss: 0.5004 - val_accuracy: 0.7949\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4270 - accuracy: 0.7845 - val_loss: 0.5056 - val_accuracy: 0.7949\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4337 - accuracy: 0.7816 - val_loss: 0.5044 - val_accuracy: 0.7949\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.4269 - accuracy: 0.7644 - val_loss: 0.5166 - val_accuracy: 0.7949\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4262 - accuracy: 0.7816 - val_loss: 0.5066 - val_accuracy: 0.7949\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4236 - accuracy: 0.7960 - val_loss: 0.5024 - val_accuracy: 0.7949\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4191 - accuracy: 0.7730 - val_loss: 0.5086 - val_accuracy: 0.8205\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4251 - accuracy: 0.7874 - val_loss: 0.5118 - val_accuracy: 0.8205\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4184 - accuracy: 0.7816 - val_loss: 0.5089 - val_accuracy: 0.7949\n",
      "Epoch 121/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4201 - accuracy: 0.7816 - val_loss: 0.5123 - val_accuracy: 0.7949\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4276 - accuracy: 0.7845 - val_loss: 0.5141 - val_accuracy: 0.8205\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4095 - accuracy: 0.7644 - val_loss: 0.5126 - val_accuracy: 0.7949\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4250 - accuracy: 0.7730 - val_loss: 0.5169 - val_accuracy: 0.8205\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4269 - accuracy: 0.7816 - val_loss: 0.5241 - val_accuracy: 0.8205\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4222 - accuracy: 0.7644 - val_loss: 0.5316 - val_accuracy: 0.8205\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4163 - accuracy: 0.7960 - val_loss: 0.5221 - val_accuracy: 0.8205\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4177 - accuracy: 0.7730 - val_loss: 0.5205 - val_accuracy: 0.8205\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4228 - accuracy: 0.7787 - val_loss: 0.5178 - val_accuracy: 0.8205\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4248 - accuracy: 0.7816 - val_loss: 0.5327 - val_accuracy: 0.7949\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4109 - accuracy: 0.7845 - val_loss: 0.5305 - val_accuracy: 0.8205\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4069 - accuracy: 0.7874 - val_loss: 0.5191 - val_accuracy: 0.8205\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4127 - accuracy: 0.7845 - val_loss: 0.5295 - val_accuracy: 0.8205\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.4234 - accuracy: 0.7787 - val_loss: 0.5410 - val_accuracy: 0.7949\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.4092 - accuracy: 0.7931 - val_loss: 0.5206 - val_accuracy: 0.8205\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4179 - accuracy: 0.7816 - val_loss: 0.5397 - val_accuracy: 0.8205\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3950 - accuracy: 0.7960 - val_loss: 0.5438 - val_accuracy: 0.8205\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4174 - accuracy: 0.7759 - val_loss: 0.5471 - val_accuracy: 0.8205\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4053 - accuracy: 0.7816 - val_loss: 0.5442 - val_accuracy: 0.8205\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4091 - accuracy: 0.7874 - val_loss: 0.5322 - val_accuracy: 0.8205\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.4203 - accuracy: 0.7931 - val_loss: 0.5511 - val_accuracy: 0.8205\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4155 - accuracy: 0.7787 - val_loss: 0.5463 - val_accuracy: 0.7949\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.4019 - accuracy: 0.7845 - val_loss: 0.5507 - val_accuracy: 0.8205\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4129 - accuracy: 0.7845 - val_loss: 0.5513 - val_accuracy: 0.8205\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4072 - accuracy: 0.7759 - val_loss: 0.5580 - val_accuracy: 0.8205\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4149 - accuracy: 0.7989 - val_loss: 0.5505 - val_accuracy: 0.7949\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4052 - accuracy: 0.7931 - val_loss: 0.5644 - val_accuracy: 0.8205\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4033 - accuracy: 0.7989 - val_loss: 0.5679 - val_accuracy: 0.7949\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4061 - accuracy: 0.8046 - val_loss: 0.5457 - val_accuracy: 0.8205\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4119 - accuracy: 0.7931 - val_loss: 0.5670 - val_accuracy: 0.8205\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4090 - accuracy: 0.7845 - val_loss: 0.5751 - val_accuracy: 0.7949\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4109 - accuracy: 0.7845 - val_loss: 0.5782 - val_accuracy: 0.8205\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4129 - accuracy: 0.7787 - val_loss: 0.5526 - val_accuracy: 0.8205\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3996 - accuracy: 0.7931 - val_loss: 0.5508 - val_accuracy: 0.8205\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3955 - accuracy: 0.7902 - val_loss: 0.5612 - val_accuracy: 0.7949\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4139 - accuracy: 0.7644 - val_loss: 0.5781 - val_accuracy: 0.8205\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4027 - accuracy: 0.7874 - val_loss: 0.5661 - val_accuracy: 0.8205\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.4150 - accuracy: 0.7816 - val_loss: 0.5603 - val_accuracy: 0.7949\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4013 - accuracy: 0.7931 - val_loss: 0.5642 - val_accuracy: 0.7949\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4022 - accuracy: 0.7759 - val_loss: 0.5655 - val_accuracy: 0.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3989 - accuracy: 0.7816 - val_loss: 0.5747 - val_accuracy: 0.8205\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.4046 - accuracy: 0.7730 - val_loss: 0.5903 - val_accuracy: 0.7949\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3998 - accuracy: 0.7931 - val_loss: 0.5750 - val_accuracy: 0.8205\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 115us/step - loss: 0.3956 - accuracy: 0.7931 - val_loss: 0.5704 - val_accuracy: 0.7949\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3871 - accuracy: 0.7989 - val_loss: 0.5880 - val_accuracy: 0.7949\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4162 - accuracy: 0.7672 - val_loss: 0.5746 - val_accuracy: 0.7949\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4076 - accuracy: 0.7816 - val_loss: 0.5760 - val_accuracy: 0.7949\n",
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3931 - accuracy: 0.7787 - val_loss: 0.5693 - val_accuracy: 0.7949\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3930 - accuracy: 0.8017 - val_loss: 0.5872 - val_accuracy: 0.8205\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3906 - accuracy: 0.8103 - val_loss: 0.5874 - val_accuracy: 0.8205\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4039 - accuracy: 0.7931 - val_loss: 0.5837 - val_accuracy: 0.7949\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.4013 - accuracy: 0.7874 - val_loss: 0.5852 - val_accuracy: 0.8205\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4004 - accuracy: 0.7960 - val_loss: 0.5771 - val_accuracy: 0.8205\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3856 - accuracy: 0.7931 - val_loss: 0.5911 - val_accuracy: 0.7949\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3884 - accuracy: 0.7874 - val_loss: 0.5942 - val_accuracy: 0.7949\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3830 - accuracy: 0.7989 - val_loss: 0.5960 - val_accuracy: 0.8205\n",
      "Epoch 177/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.4090 - accuracy: 0.7845 - val_loss: 0.5923 - val_accuracy: 0.7949\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3900 - accuracy: 0.7989 - val_loss: 0.5969 - val_accuracy: 0.8205\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.4078 - accuracy: 0.7701 - val_loss: 0.5860 - val_accuracy: 0.8205\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3898 - accuracy: 0.7989 - val_loss: 0.5994 - val_accuracy: 0.8205\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.4053 - accuracy: 0.7759 - val_loss: 0.5753 - val_accuracy: 0.8205\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3865 - accuracy: 0.8103 - val_loss: 0.5939 - val_accuracy: 0.7949\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3935 - accuracy: 0.7931 - val_loss: 0.6010 - val_accuracy: 0.8205\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3898 - accuracy: 0.8046 - val_loss: 0.5941 - val_accuracy: 0.8205\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3711 - accuracy: 0.8017 - val_loss: 0.6106 - val_accuracy: 0.8205\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3825 - accuracy: 0.7845 - val_loss: 0.6126 - val_accuracy: 0.8205\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3868 - accuracy: 0.7989 - val_loss: 0.6224 - val_accuracy: 0.8205\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.4031 - accuracy: 0.7960 - val_loss: 0.6345 - val_accuracy: 0.7949\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.3867 - accuracy: 0.7759 - val_loss: 0.6320 - val_accuracy: 0.7949\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3848 - accuracy: 0.8132 - val_loss: 0.6463 - val_accuracy: 0.7949\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3792 - accuracy: 0.7960 - val_loss: 0.6415 - val_accuracy: 0.8205\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3972 - accuracy: 0.7931 - val_loss: 0.6233 - val_accuracy: 0.7949\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.3865 - accuracy: 0.7989 - val_loss: 0.6501 - val_accuracy: 0.7949\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.3793 - accuracy: 0.7874 - val_loss: 0.6607 - val_accuracy: 0.8205\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.3919 - accuracy: 0.7845 - val_loss: 0.6272 - val_accuracy: 0.8205\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.3856 - accuracy: 0.8017 - val_loss: 0.6290 - val_accuracy: 0.8205\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.3982 - accuracy: 0.7960 - val_loss: 0.6494 - val_accuracy: 0.8205\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3960 - accuracy: 0.7874 - val_loss: 0.6405 - val_accuracy: 0.8205\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.3754 - accuracy: 0.7931 - val_loss: 0.6354 - val_accuracy: 0.8205\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.3873 - accuracy: 0.7902 - val_loss: 0.6544 - val_accuracy: 0.8205\n",
      "Predicted: [[5.4504114e-01]\n",
      " [1.9973919e-01]\n",
      " [2.2016138e-02]\n",
      " [2.2158462e-01]\n",
      " [8.6265802e-04]\n",
      " [4.3899176e-01]\n",
      " [5.2824652e-01]\n",
      " [2.7773994e-01]\n",
      " [1.4070547e-01]\n",
      " [6.7075980e-01]\n",
      " [1.6430020e-04]\n",
      " [1.7803881e-01]\n",
      " [3.7696958e-04]\n",
      " [1.3680387e-01]\n",
      " [6.1057001e-01]\n",
      " [4.0619677e-01]\n",
      " [2.1442524e-01]\n",
      " [2.0462251e-01]\n",
      " [2.0861626e-07]\n",
      " [5.8843493e-03]\n",
      " [5.0320923e-03]\n",
      " [1.9641551e-01]\n",
      " [3.8588971e-01]\n",
      " [1.4796853e-04]\n",
      " [2.0193648e-01]\n",
      " [1.2503761e-01]\n",
      " [6.2001294e-01]\n",
      " [3.5634637e-04]\n",
      " [5.6573218e-01]\n",
      " [4.8903698e-01]\n",
      " [1.5699863e-04]\n",
      " [1.1071175e-02]\n",
      " [1.9075200e-01]\n",
      " [6.2608927e-01]\n",
      " [6.4895809e-02]\n",
      " [1.1997312e-02]\n",
      " [1.8262953e-02]\n",
      " [2.7194023e-03]\n",
      " [0.0000000e+00]\n",
      " [4.1775715e-01]\n",
      " [6.4627416e-06]\n",
      " [2.0898438e-01]\n",
      " [7.3434371e-01]]\n",
      "Actual: [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "43/43 [==============================] - 0s 47us/step\n",
      "Eval: [0.5301950819963632, 0.7441860437393188]\n",
      "------------------------------------------------\n",
      "Train on 348 samples, validate on 39 samples\n",
      "Epoch 1/200\n",
      "348/348 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.8534 - val_loss: 0.4726 - val_accuracy: 0.9744\n",
      "Epoch 2/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.3900 - accuracy: 0.9368 - val_loss: 0.2262 - val_accuracy: 0.9744\n",
      "Epoch 3/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2487 - accuracy: 0.9368 - val_loss: 0.1266 - val_accuracy: 0.9744\n",
      "Epoch 4/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.2501 - accuracy: 0.9368 - val_loss: 0.1176 - val_accuracy: 0.9744\n",
      "Epoch 5/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.2406 - accuracy: 0.9368 - val_loss: 0.1230 - val_accuracy: 0.9744\n",
      "Epoch 6/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2316 - accuracy: 0.9368 - val_loss: 0.1246 - val_accuracy: 0.9744\n",
      "Epoch 7/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.2280 - accuracy: 0.9368 - val_loss: 0.1238 - val_accuracy: 0.9744\n",
      "Epoch 8/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2186 - accuracy: 0.9368 - val_loss: 0.1206 - val_accuracy: 0.9744\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.2171 - accuracy: 0.9368 - val_loss: 0.1164 - val_accuracy: 0.9744\n",
      "Epoch 10/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2103 - accuracy: 0.9368 - val_loss: 0.1116 - val_accuracy: 0.9744\n",
      "Epoch 11/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.2014 - accuracy: 0.9368 - val_loss: 0.1100 - val_accuracy: 0.9744\n",
      "Epoch 12/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.2065 - accuracy: 0.9368 - val_loss: 0.1078 - val_accuracy: 0.9744\n",
      "Epoch 13/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1937 - accuracy: 0.9368 - val_loss: 0.1063 - val_accuracy: 0.9744\n",
      "Epoch 14/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1982 - accuracy: 0.9368 - val_loss: 0.1054 - val_accuracy: 0.9744\n",
      "Epoch 15/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1985 - accuracy: 0.9368 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "Epoch 16/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1879 - accuracy: 0.9368 - val_loss: 0.1094 - val_accuracy: 0.9744\n",
      "Epoch 17/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1790 - accuracy: 0.9368 - val_loss: 0.1054 - val_accuracy: 0.9744\n",
      "Epoch 18/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1973 - accuracy: 0.9368 - val_loss: 0.1025 - val_accuracy: 0.9744\n",
      "Epoch 19/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1850 - accuracy: 0.9368 - val_loss: 0.1071 - val_accuracy: 0.9744\n",
      "Epoch 20/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1929 - accuracy: 0.9368 - val_loss: 0.1039 - val_accuracy: 0.9744\n",
      "Epoch 21/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1844 - accuracy: 0.9368 - val_loss: 0.1013 - val_accuracy: 0.9744\n",
      "Epoch 22/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1827 - accuracy: 0.9368 - val_loss: 0.1129 - val_accuracy: 0.9744\n",
      "Epoch 23/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1778 - accuracy: 0.9368 - val_loss: 0.1075 - val_accuracy: 0.9744\n",
      "Epoch 24/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1778 - accuracy: 0.9397 - val_loss: 0.1024 - val_accuracy: 0.9744\n",
      "Epoch 25/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1776 - accuracy: 0.9368 - val_loss: 0.1084 - val_accuracy: 0.9744\n",
      "Epoch 26/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1723 - accuracy: 0.9339 - val_loss: 0.1040 - val_accuracy: 0.9744\n",
      "Epoch 27/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1711 - accuracy: 0.9397 - val_loss: 0.1090 - val_accuracy: 0.9744\n",
      "Epoch 28/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1750 - accuracy: 0.9454 - val_loss: 0.1145 - val_accuracy: 0.9744\n",
      "Epoch 29/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1680 - accuracy: 0.9310 - val_loss: 0.1047 - val_accuracy: 0.9744\n",
      "Epoch 30/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1736 - accuracy: 0.9368 - val_loss: 0.1026 - val_accuracy: 0.9744\n",
      "Epoch 31/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1731 - accuracy: 0.9397 - val_loss: 0.1080 - val_accuracy: 0.9744\n",
      "Epoch 32/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1729 - accuracy: 0.9339 - val_loss: 0.1161 - val_accuracy: 0.9487\n",
      "Epoch 33/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1760 - accuracy: 0.9397 - val_loss: 0.1179 - val_accuracy: 0.9487\n",
      "Epoch 34/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1829 - accuracy: 0.9483 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 35/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1647 - accuracy: 0.9454 - val_loss: 0.1067 - val_accuracy: 0.9744\n",
      "Epoch 36/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1714 - accuracy: 0.9425 - val_loss: 0.1148 - val_accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1734 - accuracy: 0.9310 - val_loss: 0.1155 - val_accuracy: 0.9487\n",
      "Epoch 38/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1594 - accuracy: 0.9425 - val_loss: 0.1098 - val_accuracy: 0.9744\n",
      "Epoch 39/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1684 - accuracy: 0.9339 - val_loss: 0.1087 - val_accuracy: 0.9744\n",
      "Epoch 40/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1752 - accuracy: 0.9425 - val_loss: 0.1201 - val_accuracy: 0.9487\n",
      "Epoch 41/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.1766 - accuracy: 0.9339 - val_loss: 0.1168 - val_accuracy: 0.9744\n",
      "Epoch 42/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1701 - accuracy: 0.9397 - val_loss: 0.1115 - val_accuracy: 0.9744\n",
      "Epoch 43/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1683 - accuracy: 0.9368 - val_loss: 0.1113 - val_accuracy: 0.9744\n",
      "Epoch 44/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1645 - accuracy: 0.9425 - val_loss: 0.1165 - val_accuracy: 0.9487\n",
      "Epoch 45/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1651 - accuracy: 0.9397 - val_loss: 0.1151 - val_accuracy: 0.9487\n",
      "Epoch 46/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1722 - accuracy: 0.9339 - val_loss: 0.1113 - val_accuracy: 0.9487\n",
      "Epoch 47/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1679 - accuracy: 0.9397 - val_loss: 0.1146 - val_accuracy: 0.9487\n",
      "Epoch 48/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1668 - accuracy: 0.9425 - val_loss: 0.1189 - val_accuracy: 0.9487\n",
      "Epoch 49/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1649 - accuracy: 0.9339 - val_loss: 0.1171 - val_accuracy: 0.9487\n",
      "Epoch 50/200\n",
      "348/348 [==============================] - 0s 121us/step - loss: 0.1772 - accuracy: 0.9310 - val_loss: 0.1075 - val_accuracy: 0.9744\n",
      "Epoch 51/200\n",
      "348/348 [==============================] - 0s 132us/step - loss: 0.1585 - accuracy: 0.9425 - val_loss: 0.1234 - val_accuracy: 0.9487\n",
      "Epoch 52/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1660 - accuracy: 0.9425 - val_loss: 0.1119 - val_accuracy: 0.9487\n",
      "Epoch 53/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1586 - accuracy: 0.9310 - val_loss: 0.1108 - val_accuracy: 0.9744\n",
      "Epoch 54/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1694 - accuracy: 0.9310 - val_loss: 0.1115 - val_accuracy: 0.9744\n",
      "Epoch 55/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1533 - accuracy: 0.9339 - val_loss: 0.1093 - val_accuracy: 0.9744\n",
      "Epoch 56/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1738 - accuracy: 0.9397 - val_loss: 0.1089 - val_accuracy: 0.9744\n",
      "Epoch 57/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1704 - accuracy: 0.9425 - val_loss: 0.1137 - val_accuracy: 0.9487\n",
      "Epoch 58/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1679 - accuracy: 0.9397 - val_loss: 0.1155 - val_accuracy: 0.9487\n",
      "Epoch 59/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1592 - accuracy: 0.9368 - val_loss: 0.1055 - val_accuracy: 0.9744\n",
      "Epoch 60/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1586 - accuracy: 0.9425 - val_loss: 0.1103 - val_accuracy: 0.9744\n",
      "Epoch 61/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.1578 - accuracy: 0.9397 - val_loss: 0.1144 - val_accuracy: 0.9487\n",
      "Epoch 62/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1617 - accuracy: 0.9425 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 63/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1654 - accuracy: 0.9282 - val_loss: 0.1158 - val_accuracy: 0.9487\n",
      "Epoch 64/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1605 - accuracy: 0.9368 - val_loss: 0.1053 - val_accuracy: 0.9487\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 106us/step - loss: 0.1665 - accuracy: 0.9397 - val_loss: 0.1133 - val_accuracy: 0.9487\n",
      "Epoch 66/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1598 - accuracy: 0.9397 - val_loss: 0.1170 - val_accuracy: 0.9487\n",
      "Epoch 67/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1540 - accuracy: 0.9425 - val_loss: 0.1170 - val_accuracy: 0.9487\n",
      "Epoch 68/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1560 - accuracy: 0.9397 - val_loss: 0.1191 - val_accuracy: 0.9487\n",
      "Epoch 69/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1700 - accuracy: 0.9425 - val_loss: 0.1131 - val_accuracy: 0.9744\n",
      "Epoch 70/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1480 - accuracy: 0.9540 - val_loss: 0.1126 - val_accuracy: 0.9487\n",
      "Epoch 71/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1508 - accuracy: 0.9454 - val_loss: 0.1147 - val_accuracy: 0.9487\n",
      "Epoch 72/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1581 - accuracy: 0.9454 - val_loss: 0.1144 - val_accuracy: 0.9487\n",
      "Epoch 73/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1661 - accuracy: 0.9368 - val_loss: 0.1166 - val_accuracy: 0.9487\n",
      "Epoch 74/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1655 - accuracy: 0.9339 - val_loss: 0.1299 - val_accuracy: 0.9487\n",
      "Epoch 75/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1652 - accuracy: 0.9483 - val_loss: 0.1153 - val_accuracy: 0.9487\n",
      "Epoch 76/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1542 - accuracy: 0.9454 - val_loss: 0.1187 - val_accuracy: 0.9487\n",
      "Epoch 77/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1588 - accuracy: 0.9425 - val_loss: 0.1167 - val_accuracy: 0.9487\n",
      "Epoch 78/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1631 - accuracy: 0.9425 - val_loss: 0.1071 - val_accuracy: 0.9744\n",
      "Epoch 79/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1622 - accuracy: 0.9368 - val_loss: 0.1103 - val_accuracy: 0.9744\n",
      "Epoch 80/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1560 - accuracy: 0.9397 - val_loss: 0.1176 - val_accuracy: 0.9744\n",
      "Epoch 81/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1463 - accuracy: 0.9397 - val_loss: 0.1152 - val_accuracy: 0.9487\n",
      "Epoch 82/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1645 - accuracy: 0.9397 - val_loss: 0.1152 - val_accuracy: 0.9487\n",
      "Epoch 83/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1538 - accuracy: 0.9425 - val_loss: 0.1183 - val_accuracy: 0.9744\n",
      "Epoch 84/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1603 - accuracy: 0.9425 - val_loss: 0.1091 - val_accuracy: 0.9744\n",
      "Epoch 85/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1501 - accuracy: 0.9425 - val_loss: 0.1126 - val_accuracy: 0.9744\n",
      "Epoch 86/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1602 - accuracy: 0.9397 - val_loss: 0.1157 - val_accuracy: 0.9744\n",
      "Epoch 87/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1621 - accuracy: 0.9282 - val_loss: 0.1141 - val_accuracy: 0.9744\n",
      "Epoch 88/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1586 - accuracy: 0.9397 - val_loss: 0.1118 - val_accuracy: 0.9744\n",
      "Epoch 89/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1574 - accuracy: 0.9483 - val_loss: 0.1160 - val_accuracy: 0.9744\n",
      "Epoch 90/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1542 - accuracy: 0.9483 - val_loss: 0.0988 - val_accuracy: 0.9744\n",
      "Epoch 91/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1583 - accuracy: 0.9425 - val_loss: 0.1133 - val_accuracy: 0.9744\n",
      "Epoch 92/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1486 - accuracy: 0.9540 - val_loss: 0.1162 - val_accuracy: 0.9744\n",
      "Epoch 93/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1531 - accuracy: 0.9425 - val_loss: 0.1147 - val_accuracy: 0.9487\n",
      "Epoch 94/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1570 - accuracy: 0.9454 - val_loss: 0.1232 - val_accuracy: 0.9487\n",
      "Epoch 95/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1509 - accuracy: 0.9425 - val_loss: 0.1253 - val_accuracy: 0.9487\n",
      "Epoch 96/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1546 - accuracy: 0.9511 - val_loss: 0.1014 - val_accuracy: 0.9744\n",
      "Epoch 97/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1707 - accuracy: 0.9425 - val_loss: 0.1178 - val_accuracy: 0.9744\n",
      "Epoch 98/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1590 - accuracy: 0.9397 - val_loss: 0.1327 - val_accuracy: 0.9487\n",
      "Epoch 99/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1493 - accuracy: 0.9368 - val_loss: 0.1173 - val_accuracy: 0.9487\n",
      "Epoch 100/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1431 - accuracy: 0.9425 - val_loss: 0.1178 - val_accuracy: 0.9487\n",
      "Epoch 101/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1543 - accuracy: 0.9397 - val_loss: 0.1160 - val_accuracy: 0.9487\n",
      "Epoch 102/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1461 - accuracy: 0.9368 - val_loss: 0.1175 - val_accuracy: 0.9487\n",
      "Epoch 103/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1463 - accuracy: 0.9397 - val_loss: 0.1087 - val_accuracy: 0.9487\n",
      "Epoch 104/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.1515 - accuracy: 0.9511 - val_loss: 0.1080 - val_accuracy: 0.9744\n",
      "Epoch 105/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1428 - accuracy: 0.9454 - val_loss: 0.1113 - val_accuracy: 0.9744\n",
      "Epoch 106/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1461 - accuracy: 0.9454 - val_loss: 0.1268 - val_accuracy: 0.9487\n",
      "Epoch 107/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1589 - accuracy: 0.9339 - val_loss: 0.1145 - val_accuracy: 0.9487\n",
      "Epoch 108/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1489 - accuracy: 0.9425 - val_loss: 0.1184 - val_accuracy: 0.9487\n",
      "Epoch 109/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1448 - accuracy: 0.9454 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 110/200\n",
      "348/348 [==============================] - 0s 109us/step - loss: 0.1523 - accuracy: 0.9425 - val_loss: 0.1104 - val_accuracy: 0.9744\n",
      "Epoch 111/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1438 - accuracy: 0.9425 - val_loss: 0.0990 - val_accuracy: 0.9744\n",
      "Epoch 112/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1581 - accuracy: 0.9368 - val_loss: 0.1133 - val_accuracy: 0.9487\n",
      "Epoch 113/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1497 - accuracy: 0.9483 - val_loss: 0.1241 - val_accuracy: 0.9487\n",
      "Epoch 114/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1513 - accuracy: 0.9454 - val_loss: 0.1160 - val_accuracy: 0.9487\n",
      "Epoch 115/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1622 - accuracy: 0.9425 - val_loss: 0.1063 - val_accuracy: 0.9744\n",
      "Epoch 116/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1498 - accuracy: 0.9397 - val_loss: 0.1176 - val_accuracy: 0.9487\n",
      "Epoch 117/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1480 - accuracy: 0.9397 - val_loss: 0.1258 - val_accuracy: 0.9487\n",
      "Epoch 118/200\n",
      "348/348 [==============================] - 0s 118us/step - loss: 0.1557 - accuracy: 0.9425 - val_loss: 0.1146 - val_accuracy: 0.9487\n",
      "Epoch 119/200\n",
      "348/348 [==============================] - 0s 124us/step - loss: 0.1399 - accuracy: 0.9483 - val_loss: 0.1097 - val_accuracy: 0.9487\n",
      "Epoch 120/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1674 - accuracy: 0.9425 - val_loss: 0.1031 - val_accuracy: 0.9487\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 95us/step - loss: 0.1527 - accuracy: 0.9483 - val_loss: 0.1187 - val_accuracy: 0.9487\n",
      "Epoch 122/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1431 - accuracy: 0.9454 - val_loss: 0.1291 - val_accuracy: 0.9487\n",
      "Epoch 123/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1454 - accuracy: 0.9454 - val_loss: 0.1177 - val_accuracy: 0.9744\n",
      "Epoch 124/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1471 - accuracy: 0.9511 - val_loss: 0.1179 - val_accuracy: 0.9487\n",
      "Epoch 125/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1511 - accuracy: 0.9425 - val_loss: 0.1120 - val_accuracy: 0.9487\n",
      "Epoch 126/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1439 - accuracy: 0.9454 - val_loss: 0.1193 - val_accuracy: 0.9487\n",
      "Epoch 127/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1480 - accuracy: 0.9397 - val_loss: 0.1221 - val_accuracy: 0.9487\n",
      "Epoch 128/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1499 - accuracy: 0.9454 - val_loss: 0.1102 - val_accuracy: 0.9487\n",
      "Epoch 129/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1503 - accuracy: 0.9540 - val_loss: 0.0998 - val_accuracy: 0.9744\n",
      "Epoch 130/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1506 - accuracy: 0.9339 - val_loss: 0.1228 - val_accuracy: 0.9487\n",
      "Epoch 131/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1490 - accuracy: 0.9483 - val_loss: 0.1167 - val_accuracy: 0.9487\n",
      "Epoch 132/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1514 - accuracy: 0.9483 - val_loss: 0.1158 - val_accuracy: 0.9744\n",
      "Epoch 133/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1314 - accuracy: 0.9483 - val_loss: 0.1123 - val_accuracy: 0.9744\n",
      "Epoch 134/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1459 - accuracy: 0.9425 - val_loss: 0.1093 - val_accuracy: 0.9744\n",
      "Epoch 135/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1424 - accuracy: 0.9511 - val_loss: 0.1175 - val_accuracy: 0.9487\n",
      "Epoch 136/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1507 - accuracy: 0.9483 - val_loss: 0.1092 - val_accuracy: 0.9744\n",
      "Epoch 137/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1453 - accuracy: 0.9425 - val_loss: 0.1138 - val_accuracy: 0.9487\n",
      "Epoch 138/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1367 - accuracy: 0.9511 - val_loss: 0.1114 - val_accuracy: 0.9487\n",
      "Epoch 139/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1434 - accuracy: 0.9511 - val_loss: 0.1213 - val_accuracy: 0.9487\n",
      "Epoch 140/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1363 - accuracy: 0.9483 - val_loss: 0.1070 - val_accuracy: 0.9744\n",
      "Epoch 141/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1408 - accuracy: 0.9483 - val_loss: 0.1008 - val_accuracy: 0.9744\n",
      "Epoch 142/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1510 - accuracy: 0.9454 - val_loss: 0.1214 - val_accuracy: 0.9487\n",
      "Epoch 143/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1396 - accuracy: 0.9454 - val_loss: 0.1135 - val_accuracy: 0.9487\n",
      "Epoch 144/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1490 - accuracy: 0.9454 - val_loss: 0.1143 - val_accuracy: 0.9487\n",
      "Epoch 145/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1405 - accuracy: 0.9483 - val_loss: 0.1047 - val_accuracy: 0.9487\n",
      "Epoch 146/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1427 - accuracy: 0.9483 - val_loss: 0.1052 - val_accuracy: 0.9744\n",
      "Epoch 147/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1340 - accuracy: 0.9511 - val_loss: 0.1106 - val_accuracy: 0.9744\n",
      "Epoch 148/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1497 - accuracy: 0.9540 - val_loss: 0.1202 - val_accuracy: 0.9487\n",
      "Epoch 149/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1465 - accuracy: 0.9454 - val_loss: 0.1151 - val_accuracy: 0.9487\n",
      "Epoch 150/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1500 - accuracy: 0.9454 - val_loss: 0.1182 - val_accuracy: 0.9487\n",
      "Epoch 151/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1384 - accuracy: 0.9511 - val_loss: 0.1177 - val_accuracy: 0.9487\n",
      "Epoch 152/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1335 - accuracy: 0.9454 - val_loss: 0.0984 - val_accuracy: 0.9744\n",
      "Epoch 153/200\n",
      "348/348 [==============================] - 0s 83us/step - loss: 0.1411 - accuracy: 0.9483 - val_loss: 0.1089 - val_accuracy: 0.9487\n",
      "Epoch 154/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1399 - accuracy: 0.9454 - val_loss: 0.1239 - val_accuracy: 0.9487\n",
      "Epoch 155/200\n",
      "348/348 [==============================] - 0s 86us/step - loss: 0.1557 - accuracy: 0.9511 - val_loss: 0.1218 - val_accuracy: 0.9487\n",
      "Epoch 156/200\n",
      "348/348 [==============================] - 0s 89us/step - loss: 0.1450 - accuracy: 0.9511 - val_loss: 0.1080 - val_accuracy: 0.9744\n",
      "Epoch 157/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1390 - accuracy: 0.9569 - val_loss: 0.1165 - val_accuracy: 0.9744\n",
      "Epoch 158/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1416 - accuracy: 0.9511 - val_loss: 0.1156 - val_accuracy: 0.9487\n",
      "Epoch 159/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1437 - accuracy: 0.9511 - val_loss: 0.1152 - val_accuracy: 0.9487\n",
      "Epoch 160/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1446 - accuracy: 0.9425 - val_loss: 0.1149 - val_accuracy: 0.9487\n",
      "Epoch 161/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1359 - accuracy: 0.9483 - val_loss: 0.1292 - val_accuracy: 0.9487\n",
      "Epoch 162/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1427 - accuracy: 0.9454 - val_loss: 0.1136 - val_accuracy: 0.9487\n",
      "Epoch 163/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1359 - accuracy: 0.9483 - val_loss: 0.1294 - val_accuracy: 0.9487\n",
      "Epoch 164/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1461 - accuracy: 0.9397 - val_loss: 0.1219 - val_accuracy: 0.9487\n",
      "Epoch 165/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1490 - accuracy: 0.9483 - val_loss: 0.1153 - val_accuracy: 0.9487\n",
      "Epoch 166/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1365 - accuracy: 0.9454 - val_loss: 0.1167 - val_accuracy: 0.9744\n",
      "Epoch 167/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1395 - accuracy: 0.9483 - val_loss: 0.1162 - val_accuracy: 0.9744\n",
      "Epoch 168/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1288 - accuracy: 0.9540 - val_loss: 0.1180 - val_accuracy: 0.9487\n",
      "Epoch 169/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1392 - accuracy: 0.9483 - val_loss: 0.1329 - val_accuracy: 0.9487\n",
      "Epoch 170/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1401 - accuracy: 0.9511 - val_loss: 0.1224 - val_accuracy: 0.9744\n",
      "Epoch 171/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1361 - accuracy: 0.9397 - val_loss: 0.1112 - val_accuracy: 0.9744\n",
      "Epoch 172/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1480 - accuracy: 0.9425 - val_loss: 0.1108 - val_accuracy: 0.9487\n",
      "Epoch 173/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1272 - accuracy: 0.9569 - val_loss: 0.1131 - val_accuracy: 0.9487\n",
      "Epoch 174/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1240 - accuracy: 0.9540 - val_loss: 0.1041 - val_accuracy: 0.9744\n",
      "Epoch 175/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1394 - accuracy: 0.9454 - val_loss: 0.1008 - val_accuracy: 0.9744\n",
      "Epoch 176/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1465 - accuracy: 0.9483 - val_loss: 0.1053 - val_accuracy: 0.9744\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/348 [==============================] - 0s 101us/step - loss: 0.1401 - accuracy: 0.9425 - val_loss: 0.1034 - val_accuracy: 0.9487\n",
      "Epoch 178/200\n",
      "348/348 [==============================] - 0s 112us/step - loss: 0.1332 - accuracy: 0.9454 - val_loss: 0.1026 - val_accuracy: 0.9744\n",
      "Epoch 179/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1395 - accuracy: 0.9425 - val_loss: 0.1148 - val_accuracy: 0.9744\n",
      "Epoch 180/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1196 - accuracy: 0.9569 - val_loss: 0.1031 - val_accuracy: 0.9744\n",
      "Epoch 181/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1345 - accuracy: 0.9511 - val_loss: 0.1121 - val_accuracy: 0.9744\n",
      "Epoch 182/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1397 - accuracy: 0.9511 - val_loss: 0.1057 - val_accuracy: 0.9744\n",
      "Epoch 183/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1347 - accuracy: 0.9540 - val_loss: 0.1137 - val_accuracy: 0.9744\n",
      "Epoch 184/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1368 - accuracy: 0.9483 - val_loss: 0.0943 - val_accuracy: 0.9744\n",
      "Epoch 185/200\n",
      "348/348 [==============================] - 0s 106us/step - loss: 0.1521 - accuracy: 0.9454 - val_loss: 0.1172 - val_accuracy: 0.9487\n",
      "Epoch 186/200\n",
      "348/348 [==============================] - 0s 104us/step - loss: 0.1237 - accuracy: 0.9569 - val_loss: 0.1256 - val_accuracy: 0.9744\n",
      "Epoch 187/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1403 - accuracy: 0.9454 - val_loss: 0.1089 - val_accuracy: 0.9744\n",
      "Epoch 188/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1358 - accuracy: 0.9483 - val_loss: 0.1177 - val_accuracy: 0.9487\n",
      "Epoch 189/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1310 - accuracy: 0.9483 - val_loss: 0.1064 - val_accuracy: 0.9744\n",
      "Epoch 190/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1411 - accuracy: 0.9397 - val_loss: 0.1035 - val_accuracy: 0.9744\n",
      "Epoch 191/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1461 - accuracy: 0.9483 - val_loss: 0.1014 - val_accuracy: 0.9744\n",
      "Epoch 192/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1516 - accuracy: 0.9397 - val_loss: 0.1036 - val_accuracy: 0.9744\n",
      "Epoch 193/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1349 - accuracy: 0.9454 - val_loss: 0.1274 - val_accuracy: 0.9487\n",
      "Epoch 194/200\n",
      "348/348 [==============================] - 0s 98us/step - loss: 0.1358 - accuracy: 0.9540 - val_loss: 0.1132 - val_accuracy: 0.9487\n",
      "Epoch 195/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1235 - accuracy: 0.9540 - val_loss: 0.1061 - val_accuracy: 0.9487\n",
      "Epoch 196/200\n",
      "348/348 [==============================] - 0s 101us/step - loss: 0.1446 - accuracy: 0.9454 - val_loss: 0.1211 - val_accuracy: 0.9487\n",
      "Epoch 197/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1329 - accuracy: 0.9454 - val_loss: 0.1171 - val_accuracy: 0.9487\n",
      "Epoch 198/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1302 - accuracy: 0.9483 - val_loss: 0.1209 - val_accuracy: 0.9487\n",
      "Epoch 199/200\n",
      "348/348 [==============================] - 0s 95us/step - loss: 0.1326 - accuracy: 0.9511 - val_loss: 0.1075 - val_accuracy: 0.9487\n",
      "Epoch 200/200\n",
      "348/348 [==============================] - 0s 92us/step - loss: 0.1293 - accuracy: 0.9454 - val_loss: 0.1259 - val_accuracy: 0.9487\n",
      "Predicted: [[0.00000000e+00]\n",
      " [7.89880753e-04]\n",
      " [5.36053538e-01]\n",
      " [0.00000000e+00]\n",
      " [8.34465027e-07]\n",
      " [3.93390656e-06]\n",
      " [9.80198383e-05]\n",
      " [0.00000000e+00]\n",
      " [1.36748850e-02]\n",
      " [1.06692314e-05]\n",
      " [5.93066216e-06]\n",
      " [3.30805779e-06]\n",
      " [3.02760750e-01]\n",
      " [4.67896461e-06]\n",
      " [1.05572373e-01]\n",
      " [6.08904660e-02]\n",
      " [7.91847706e-05]\n",
      " [1.33983523e-01]\n",
      " [5.96046448e-08]\n",
      " [0.00000000e+00]\n",
      " [2.38418579e-07]\n",
      " [6.12827539e-01]\n",
      " [7.14515150e-02]\n",
      " [3.62115502e-02]\n",
      " [1.35302544e-04]\n",
      " [7.43266940e-03]\n",
      " [4.76865470e-02]\n",
      " [8.94069672e-08]\n",
      " [1.31130219e-06]\n",
      " [1.49404705e-02]\n",
      " [8.70227814e-06]\n",
      " [9.33110714e-05]\n",
      " [5.96046448e-08]\n",
      " [1.01840734e-01]\n",
      " [6.82537556e-02]\n",
      " [8.71738493e-02]\n",
      " [2.02655792e-06]\n",
      " [5.63263893e-05]\n",
      " [5.26067615e-03]\n",
      " [1.04960799e-03]\n",
      " [1.36834858e-02]\n",
      " [2.66054575e-03]\n",
      " [2.57967058e-05]]\n",
      "Actual: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "43/43 [==============================] - 0s 70us/step\n",
      "Eval: [0.06710006803447424, 0.9534883499145508]\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "targets=[target_1,target_2,target_3,target_4]\n",
    "weights=['P1_compliactions_nephropathy.h5','P1_compliactions_retinopathy.h5','P1_compliactions_neuropathy.h5','P1_compliactions_foot_ulcer.h5']\n",
    "for i,target in enumerate(targets):\n",
    "    model=load_model()\n",
    "    #target=np_utils.to_categorical(target)\n",
    "    train_data, test_data, train_target, test_target = train_test_split(xscale, target,test_size=0.1)\n",
    "    history=model.fit(train_data,train_target,epochs=200,validation_split=0.1)\n",
    "    model.save_weights(weights[i])\n",
    "    plot(weights[i])\n",
    "    result=model.predict(test_data)\n",
    "    print('Predicted:',result)\n",
    "    print('Actual:',test_target)\n",
    "    print('Eval:',model.evaluate(test_data,test_target))\n",
    "    print('------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00]\n",
      " [7.8988075e-04]\n",
      " [5.3605354e-01]\n",
      " [0.0000000e+00]\n",
      " [8.3446503e-07]\n",
      " [3.9339066e-06]\n",
      " [9.8019838e-05]\n",
      " [0.0000000e+00]\n",
      " [1.3674885e-02]\n",
      " [1.0669231e-05]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "results=model.predict(test_data)\n",
    "\n",
    "print(results[:10])\n",
    "print(test_target[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Diabetic Risk Level\n",
    "\n",
    "### inputs\n",
    "\n",
    "Age (y)\tGender(1, male; 2, female)\theight(cm)\tweight(kg)\tBMI(kg/m2)\tSBP(mmHg)\tDBP(mmHg)\tFPG (mmol/L)\tCholesterol(mmol/L)\tTriglyceride(mmol/L)\tHDL-c(mmol/L)\tLDL(mmol/L)\tALT(U/L)\tAST(U/L)\tBUN(mmol/L)\tCCR(umol/L)\tFPG of final visit(mmol/L)\tyear of followup\tsmoking status(1,current smoker;2, ever smoker;3,never smoker)\tdrinking status(1,current drinker;2, ever drinker;3,never drinker)\tfamily histroy of diabetes(1,Yes;0,No)\n",
    "\n",
    "### Output\n",
    "\n",
    "Probabilities (Out of 100%)\n",
    "\n",
    "censor of diabetes at followup(Out of 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('RC Health Care Data-20180820.csv').values\n",
    "data=dataset[:,0:21]\n",
    "target=dataset[:,21]\n",
    "\n",
    "#print(data[:5])\n",
    "#print(target[:5])\n",
    "\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "imp=SimpleImputer(strategy='median') #or median, most frequent etc.\n",
    "\n",
    "data=imp.fit_transform(data)\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(data)\n",
    "xscale=scaler_x.transform(data)\n",
    "np.save('data_diabetic_risk',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \n",
    "    import keras.models as models\n",
    "    import keras.layers as layers\n",
    "    import keras.optimizers as optimizers\n",
    "    from keras.layers import Dropout\n",
    "    import numpy as np\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, input_dim=21, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 171584 samples, validate on 19065 samples\n",
      "Epoch 1/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0566 - accuracy: 0.9844 - val_loss: 0.0322 - val_accuracy: 0.9899\n",
      "Epoch 2/50\n",
      "171584/171584 [==============================] - 13s 78us/step - loss: 0.0346 - accuracy: 0.9901 - val_loss: 0.0261 - val_accuracy: 0.9938\n",
      "Epoch 3/50\n",
      "171584/171584 [==============================] - 13s 78us/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0251 - val_accuracy: 0.9945\n",
      "Epoch 4/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0243 - val_accuracy: 0.9945\n",
      "Epoch 5/50\n",
      "171584/171584 [==============================] - 15s 86us/step - loss: 0.0301 - accuracy: 0.9917 - val_loss: 0.0279 - val_accuracy: 0.9923\n",
      "Epoch 6/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 0.0243 - val_accuracy: 0.9946\n",
      "Epoch 7/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.0237 - val_accuracy: 0.9945\n",
      "Epoch 8/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0289 - accuracy: 0.9923 - val_loss: 0.0236 - val_accuracy: 0.9946\n",
      "Epoch 9/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0283 - accuracy: 0.9925 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
      "Epoch 10/50\n",
      "171584/171584 [==============================] - 14s 83us/step - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0231 - val_accuracy: 0.9948\n",
      "Epoch 11/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0280 - accuracy: 0.9926 - val_loss: 0.0240 - val_accuracy: 0.9951\n",
      "Epoch 12/50\n",
      "171584/171584 [==============================] - 14s 83us/step - loss: 0.0280 - accuracy: 0.9924 - val_loss: 0.0240 - val_accuracy: 0.9938\n",
      "Epoch 13/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0239 - val_accuracy: 0.9947\n",
      "Epoch 14/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0273 - accuracy: 0.9927 - val_loss: 0.0229 - val_accuracy: 0.9952\n",
      "Epoch 15/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0268 - accuracy: 0.9928 - val_loss: 0.0230 - val_accuracy: 0.9955\n",
      "Epoch 16/50\n",
      "171584/171584 [==============================] - 13s 78us/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.0281 - val_accuracy: 0.9923\n",
      "Epoch 17/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0269 - accuracy: 0.9927 - val_loss: 0.0243 - val_accuracy: 0.9932\n",
      "Epoch 18/50\n",
      "171584/171584 [==============================] - 13s 79us/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.0230 - val_accuracy: 0.9943\n",
      "Epoch 19/50\n",
      "171584/171584 [==============================] - 14s 80us/step - loss: 0.0263 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9954\n",
      "Epoch 20/50\n",
      "171584/171584 [==============================] - 13s 78us/step - loss: 0.0257 - accuracy: 0.9934 - val_loss: 0.0230 - val_accuracy: 0.9944\n",
      "Epoch 21/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0227 - val_accuracy: 0.9946\n",
      "Epoch 22/50\n",
      "171584/171584 [==============================] - 13s 79us/step - loss: 0.0262 - accuracy: 0.9931 - val_loss: 0.0219 - val_accuracy: 0.9954\n",
      "Epoch 23/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0258 - accuracy: 0.9931 - val_loss: 0.0226 - val_accuracy: 0.9946\n",
      "Epoch 24/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.0272 - val_accuracy: 0.9922\n",
      "Epoch 25/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 0.0223 - val_accuracy: 0.9951\n",
      "Epoch 26/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0227 - val_accuracy: 0.9947\n",
      "Epoch 27/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0230 - val_accuracy: 0.9948\n",
      "Epoch 28/50\n",
      "171584/171584 [==============================] - 14s 83us/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 29/50\n",
      "171584/171584 [==============================] - 14s 83us/step - loss: 0.0253 - accuracy: 0.9936 - val_loss: 0.0227 - val_accuracy: 0.9945\n",
      "Epoch 30/50\n",
      "171584/171584 [==============================] - 14s 79us/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.0230 - val_accuracy: 0.9945\n",
      "Epoch 31/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.0243 - val_accuracy: 0.9943\n",
      "Epoch 32/50\n",
      "171584/171584 [==============================] - 13s 77us/step - loss: 0.0252 - accuracy: 0.9935 - val_loss: 0.0233 - val_accuracy: 0.9944\n",
      "Epoch 33/50\n",
      "171584/171584 [==============================] - 13s 76us/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.0229 - val_accuracy: 0.9946\n",
      "Epoch 34/50\n",
      "171584/171584 [==============================] - 14s 82us/step - loss: 0.0246 - accuracy: 0.9936 - val_loss: 0.0231 - val_accuracy: 0.9941\n",
      "Epoch 35/50\n",
      "171584/171584 [==============================] - 14s 84us/step - loss: 0.0250 - accuracy: 0.9936 - val_loss: 0.0244 - val_accuracy: 0.9941\n",
      "Epoch 36/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0249 - accuracy: 0.9934 - val_loss: 0.0221 - val_accuracy: 0.9951\n",
      "Epoch 37/50\n",
      "171584/171584 [==============================] - 15s 87us/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0235 - val_accuracy: 0.9943\n",
      "Epoch 38/50\n",
      "171584/171584 [==============================] - 13s 75us/step - loss: 0.0250 - accuracy: 0.9935 - val_loss: 0.0216 - val_accuracy: 0.9951\n",
      "Epoch 39/50\n",
      "171584/171584 [==============================] - 13s 73us/step - loss: 0.0251 - accuracy: 0.9934 - val_loss: 0.0250 - val_accuracy: 0.9938\n",
      "Epoch 40/50\n",
      "171584/171584 [==============================] - 12s 72us/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 0.0221 - val_accuracy: 0.9950\n",
      "Epoch 41/50\n",
      "171584/171584 [==============================] - 13s 73us/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.0261 - val_accuracy: 0.9928\n",
      "Epoch 42/50\n",
      "171584/171584 [==============================] - 14s 81us/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0261 - val_accuracy: 0.9924\n",
      "Epoch 43/50\n",
      "171584/171584 [==============================] - 12s 72us/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0219 - val_accuracy: 0.9954\n",
      "Epoch 44/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.0219 - val_accuracy: 0.9946\n",
      "Epoch 45/50\n",
      "171584/171584 [==============================] - 12s 70us/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0224 - val_accuracy: 0.9950\n",
      "Epoch 46/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0246 - accuracy: 0.9937 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 47/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0246 - accuracy: 0.9938 - val_loss: 0.0225 - val_accuracy: 0.9943\n",
      "Epoch 48/50\n",
      "171584/171584 [==============================] - 12s 71us/step - loss: 0.0244 - accuracy: 0.9938 - val_loss: 0.0225 - val_accuracy: 0.9952\n",
      "Epoch 49/50\n",
      "171584/171584 [==============================] - 12s 72us/step - loss: 0.0244 - accuracy: 0.9939 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
      "Epoch 50/50\n",
      "171584/171584 [==============================] - 12s 69us/step - loss: 0.0241 - accuracy: 0.9939 - val_loss: 0.0231 - val_accuracy: 0.9941\n",
      "Predicted: [[9.8258257e-05]\n",
      " [3.6427677e-03]\n",
      " [5.3942204e-05]\n",
      " ...\n",
      " [8.3386898e-05]\n",
      " [3.2007694e-05]\n",
      " [1.1828542e-04]]\n",
      "Actual: [0. 0. 0. ... 0. 0. 0.]\n",
      "21184/21184 [==============================] - 0s 22us/step\n",
      "Eval: [0.01950102641021768, 0.995468258857727]\n"
     ]
    }
   ],
   "source": [
    "model=load_model()\n",
    "#target=np_utils.to_categorical(target)\n",
    "train_data, test_data, train_target, test_target = train_test_split(xscale, target,test_size=0.1)\n",
    "history=model.fit(train_data,train_target,epochs=50,validation_split=0.1)\n",
    "model.save_weights('P1_Diabetic_Risk.h5')\n",
    "plot('P1_Diabetic_Risk.h5')\n",
    "result=model.predict(test_data)\n",
    "print('Predicted:',result)\n",
    "print('Actual:',test_target)\n",
    "print('Eval:',model.evaluate(test_data,test_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Meal Plan\n",
    "\n",
    "### Inputs\n",
    "gender\tage\tbmi\trisk level\n",
    "### Outputs\n",
    "Meal Plan (1-8 Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Target: [8. 1. 4. 4. 5. 4. 6. 3. 8. 7. 3. 8. 5. 1. 2. 2. 3. 2. 3. 1. 4. 6. 1. 2.\n",
      " 1. 6. 1. 4. 8. 1. 5. 3. 7. 5. 1. 1. 2. 4. 1. 5. 5. 6. 7. 6. 2. 5. 6. 8.\n",
      " 6. 5. 6. 3. 7. 3. 2. 4. 3. 6. 3. 7. 5. 3. 5. 7. 4. 7. 3. 7. 8. 7. 2. 1.\n",
      " 1. 2. 4. 4. 7.]\n",
      "Predicted Target: [8. 1. 4. 4. 5. 4. 6. 3. 8. 7. 3. 4. 5. 1. 2. 2. 3. 2. 3. 1. 4. 6. 1. 2.\n",
      " 1. 6. 1. 4. 8. 1. 5. 3. 7. 5. 1. 1. 2. 4. 1. 5. 5. 6. 7. 6. 2. 5. 6. 6.\n",
      " 6. 5. 6. 3. 7. 4. 2. 2. 3. 6. 3. 7. 5. 3. 5. 7. 4. 7. 3. 7. 8. 7. 2. 1.\n",
      " 1. 2. 4. 4. 7.]\n",
      "Accuracy: 0.948051948051948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2_meal_plan.sav']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('mealplan2.csv').values\n",
    "\n",
    "data=dataset[:,0:4]\n",
    "target=dataset[:,4]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#dataset splitting function\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algorithm=SVC(kernel='linear')\n",
    "#loading the KNN algorithm into \"algorithm\"\n",
    "\n",
    "algorithm.fit(train_data,train_target)\n",
    "#training\n",
    "\n",
    "result=algorithm.predict(test_data)\n",
    "#testing\n",
    "\n",
    "print('Actual Target:',test_target)\n",
    "print('Predicted Target:',result)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=accuracy_score(test_target,result)\n",
    "\n",
    "print('Accuracy:',acc)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(algorithm,'2_meal_plan.sav')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Activity Suggestion\n",
    "### Inputs\n",
    "Gender\tAge\tEmployement status\tWorking hours\tFree time in hours\tSleeping hours\tFamily time\tOther illnesses\tEmotional \n",
    "\n",
    "### Outputs\n",
    "Suggestions (Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Target: [0. 0. 0. 0. 0. 0. 1. 2. 2. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 2. 2. 2. 0. 2.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 1. 2. 0. 2. 2. 2. 2. 0. 2. 1.\n",
      " 2. 2. 2. 1. 0. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 2. 2. 0. 2. 0. 0. 2. 1. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 1. 2. 0. 0. 2. 2. 0. 0. 0. 2. 2. 2. 0. 2. 0. 0. 1. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2. 1. 0. 0. 2. 0. 0. 1. 1. 2.\n",
      " 0. 0. 0. 1. 2. 2. 2. 1. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 1. 1. 2. 0. 0. 2. 1.\n",
      " 0. 0. 2. 0. 2.]\n",
      "Predicted Target: [0. 0. 0. 0. 0. 0. 1. 2. 2. 0. 1. 0. 0. 2. 0. 0. 2. 2. 0. 2. 2. 2. 0. 2.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 2. 2. 1. 2. 0. 2. 2. 2. 2. 0. 2. 1.\n",
      " 2. 2. 2. 1. 0. 2. 2. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 2.\n",
      " 0. 2. 0. 0. 0. 0. 2. 2. 0. 2. 0. 0. 2. 1. 2. 0. 0. 0. 2. 2. 0. 0. 0. 0.\n",
      " 0. 1. 2. 0. 0. 2. 2. 0. 0. 0. 2. 2. 2. 0. 2. 0. 0. 1. 0. 0. 2. 0. 0. 0.\n",
      " 1. 0. 0. 0. 2. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2. 1. 0. 0. 2. 0. 0. 1. 1. 2.\n",
      " 0. 0. 0. 1. 2. 2. 2. 1. 0. 0. 0. 0. 0. 1. 2. 1. 0. 0. 2. 2. 0. 0. 2. 0.\n",
      " 0. 0. 0. 2. 0. 1. 0. 0. 0. 2. 2. 0. 2. 2. 0. 2. 2. 1. 1. 2. 0. 0. 2. 1.\n",
      " 0. 0. 2. 0. 2.]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4_activity_suggestion.sav']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset=pd.read_csv('depression servey-new(30th of march).csv').values\n",
    "\n",
    "data=dataset[:,0:10]\n",
    "target=dataset[:,10]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#dataset splitting function\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "algorithm=SVC(kernel='linear')\n",
    "#loading the KNN algorithm into \"algorithm\"\n",
    "\n",
    "algorithm.fit(train_data,train_target)\n",
    "#training\n",
    "\n",
    "result=algorithm.predict(test_data)\n",
    "#testing\n",
    "\n",
    "print('Actual Target:',test_target)\n",
    "print('Predicted Target:',result)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc=accuracy_score(test_target,result)\n",
    "\n",
    "print('Accuracy:',acc)\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(algorithm,'4_activity_suggestion.sav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
